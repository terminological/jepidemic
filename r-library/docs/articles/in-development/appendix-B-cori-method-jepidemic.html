<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Appendix B - Renewal equation reproduction number estimation and Jepidemic implementation validation â€¢ jepidemic</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../../bootstrap-toc.css">
<script src="../../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><meta property="og:title" content="Appendix B - Renewal equation reproduction number estimation and Jepidemic implementation validation">
<meta property="og:description" content="jepidemic">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">jepidemic</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.03</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/generating-synthetic-datasets.html">Generating synthetic datasets</a>
    </li>
    <li>
      <a href="../../articles/getting-started.html">Getting started</a>
    </li>
    <li>
      <a href="../../articles/in-development/appendix-A-validation-methods.html">Appendix A - Reproduction number validation methodology</a>
    </li>
    <li>
      <a href="../../articles/in-development/appendix-B-cori-method-jepidemic.html">Appendix B - Renewal equation reproduction number estimation and Jepidemic implementation validation</a>
    </li>
    <li>
      <a href="../../articles/in-development/appendix-C-incidence-and-growth-rate-estimation.html">Appendix C - Incidence and growth rate estimation</a>
    </li>
    <li>
      <a href="../../articles/in-development/appendix-D-bayesian-estimators.html">Appendix D - Bayesian growth rate and reproduction number estimation</a>
    </li>
    <li>
      <a href="../../articles/in-development/bayesian-growth-rate-2.html">Bayesian growth rate estimation</a>
    </li>
    <li>
      <a href="../../articles/in-development/proportion-and-growth-rate-estimation.html">Appendix C - Proportions and growth rate estimation</a>
    </li>
    <li>
      <a href="../../articles/in-development/two-strain-dynamics.html">Two strain dynamics</a>
    </li>
    <li>
      <a href="../../articles/old/cori-method.html">Cori method</a>
    </li>
    <li>
      <a href="../../articles/old/epiestim-testing.html">Testing epiestim</a>
    </li>
    <li>
      <a href="../../articles/old/growth-rate-estimation.html">Growth rate estimation</a>
    </li>
    <li>
      <a href="../../articles/old/growth-rates.html">Cori method</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Appendix B - Renewal equation reproduction number estimation and Jepidemic implementation validation</h1>
                        <h4 class="author">Rob Challen</h4>
            
            <h4 class="date">28-01-2022</h4>
      
      
      <div class="hidden name"><code>appendix-B-cori-method-jepidemic.Rmd</code></div>

    </div>

    
    
<p>This appendix provides a detailed review of the renewal equation methodology for estimating the effective reproduction number as presented by Cori et al. <span class="citation">[@coriEpiEstimEstimateTime2021; @coriNewFrameworkSoftware2013; @thompsonImprovedInferenceTimevarying2019]</span>. This supported much of the analysis contained in this thesis, and was applied to data from the SARS-CoV-2 outbreak in the UK to support the work of the Scientific Pandemic Influenza - Modelling subgroup (SPI-M) and track the progress of the epidemic in the UK. The implementation of this method changed over the course of the pandemic to address specific issue that arose. These changes have been implemented in a Java library with bindings to the R language called "jepidemic", which is open source and available on GitHub <span class="citation">[@rob_challen_2022_5820292]</span>. The implementation of this library diverges from the reference implementation, EpiEstim, and this appendix summarises those changes and quantifies the benefits expected in terms of estimation accuracy, using the validation methodology described in appendix A.</p>
<div id="review-of-the-renewal-equation-method-for-estimating-the-effective-reproduction-number-" class="section level1">
<h1 class="hasAnchor">
<a href="#review-of-the-renewal-equation-method-for-estimating-the-effective-reproduction-number-" class="anchor"></a>Review of the renewal equation method for estimating the effective reproduction number.</h1>
<p>We assume <span class="math inline">\(I_0, I_1, \dots, I_t\)</span> is a time series of infection counts, assumed to be a single sample drawn from some time varying discrete probability distribution with expected value <span class="math inline">\(\overline{I_t}\)</span>. The infectivity profile is another probability distribution, that defines the likelihood that a case infected at time <span class="math inline">\(t\)</span> resulted from a case infected between the times <span class="math inline">\(t-s\)</span> and <span class="math inline">\(t-s+1\)</span>, and as defined here most often represented in discrete form <span class="math inline">\(\omega_1, \omega_2, \dots, \omega_s\)</span>. This definition implies that <span class="math inline">\(\omega_{s \leq 0} = 0\)</span> as that would apply to secondary infections resulting from primary infections in the future. The discrete time measure <span class="math inline">\(s\)</span> here represents the upper bound of the equivalent continuous unit time interval, rather than, for example, the middle of the interval.</p>
<p>As in appendix A, we can define the backward-looking effective reproduction number as the inverse ratio of the number of primary infections that cause the secondary infections observed at time <span class="math inline">\(t\)</span>, this is known as the instantaneous reproduction number, <span class="math inline">\(R_t^i\)</span>. In an evolving epidemic the instantaneous reproduction number is able to be calculated using data that has already been observed, and is hence a more useful quantity than the other forms of the reproduction number presented in Appendix A. The rest of this summary considers only the instantaneous version of the effective reproduction number, which we refer to as the reproduction number or <span class="math inline">\(R_t\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
R_t^i &amp;= \frac{\overline{I_t}}{\sum_{s=1}^t \overline{I_{t-s}}\omega_s} \\
\end{aligned} 
\tag{eq:rt}
\]</span></p>
<p>With the definitions above, we consider the number of new cases on a day <span class="math inline">\(I_t\)</span>, to be the number of cases observed in previous time points convolved by the infectivity profile, and scaled by the reproduction number. From this we define the quantity <span class="math inline">\(\Lambda_t\)</span> as the number of primary cases that resulted in a secondary case at time <span class="math inline">\(t\)</span>, and which is the denominator in <span class="math inline">\(\eqref{eq:rt}\)</span>. This definition disregards the possible role of co-infection,l of an individual infectee by multiple infectors and assumes secondary cases result from one, and only one, primary infection.</p>
<!-- 
N.B. thinking about weighing of the observations or adjusting for weekly periodicity. 
Don't think it can be done that easily but Lambda would be the place to incorporate it 
I think. It would be nice Lambda is possible to infer in the face of missing data?
-->
<p><span class="math display">\[
\begin{aligned}
\Lambda_t &amp;= \sum_{s=1}^t I_{t-s}\omega_s \\
E[I_t| I_0,\dots,I_{t-1},\omega,R_t] &amp;= R_t\Lambda_t 
\end{aligned}
\tag{eq:lambdaS}
\]</span> We also assume that as a count of infections, the case incidence can be modelled as a Poisson distributed quantity, <span class="math inline">\(I_t \sim Pois(\lambda_t)\)</span> and therefore <span class="math inline">\(\lambda_t = \overline{I_t}\)</span>. Given the infectivity profile distribution <span class="math inline">\(\omega\)</span>, the number of cases we expect to see on a given day, is given by the Poisson distribution probability density function:</p>
<p><span class="math display">\[
\begin{aligned} 
P(I_t) &amp;= \frac{\lambda_t^{I_t} e^{-\lambda_t}}{I_t!} \\
\lambda_t &amp;\approx E[I_t| I_0,\dots,I_{t-1},\omega,R_t]\\
P(I_t | I_0,\dots,I_{t-1},\omega,R_t) &amp;= \frac{(R_t\Lambda_t)^{I_t}e^{-R_t\Lambda_t}}{I_t!} 
\end{aligned} \tag{eq:probIt}
\]</span></p>
<p>We are interested in producing estimates of the reproduction number that are conditioned on the data we have available. To do this we assume <span class="math inline">\(R_t\)</span> is constant over a short time period of <span class="math inline">\(\tau\)</span> days prior to and including the date of the estimate <span class="math inline">\([t-\tau+1;t]\)</span> (and defined as <span class="math inline">\(R_{t,\tau}\)</span>).</p>
<p>As an aside, we use the following relationship:</p>
<p><span class="math display">\[
\begin{aligned}
 P(A_3 | A_2,A_1)  \times P(A_2 | A_1)  &amp;= \\
 &amp;= \frac{P(A_3,A_2,A_1)}{P(A_2,A_1)}  \times  \frac{P(A_2 , A_1)}{P(A_1)}\\
 &amp;= \frac{P(A_3,A_2,A_1)}{P(A_1)}\\
 &amp;= P(A_3,A_2|A_1)
\end{aligned}
\]</span></p>
<p>Consider the combined probability of observing <span class="math inline">\(I_{t-\tau+1} \dots I_t\)</span>, given the other information available to us, we can express this as the product:</p>
<p><span class="math display">\[
\begin{aligned}
P(I_t | I_0,\dots,I_{t-1},\omega,R_{t,\tau}) &amp;\times \\
P(I_{t-1} | I_0,\dots,I_{t-2},\omega,R_{t,\tau})  &amp;\times  \\
P(I_{t-2} | I_0,\dots,I_{t-3},\omega,R_{t,\tau})  &amp;\times  \\
\dots &amp;\\
P(I_{t-\tau+1} | I_0,\dots,I_{t-\tau-1},\omega,R_{t,\tau})&amp; \\
&amp;= P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau})
\end{aligned}
\]</span></p>
<p>Furthermore substituting <span class="math inline">\(\eqref{eq:probIt}\)</span> for the left hand side we derive the following expression for the combined probability of observing <span class="math inline">\(I_{t-\tau+1} \dots I_t\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau}) &amp;= \prod_{s=t-\tau+1}^t\frac{(R_{t,\tau}\Lambda_s)^{I_s}e^{-R_{t,\tau}\Lambda_s}}{I_s!}
\\
&amp;=
R_{t,\tau}^{\sum_{s=t-\tau+1}^t I_s}
e^{
  -R_{t,\tau}
  \big(
    \sum_{s=t-\tau+1}^t \Lambda_s
  \big)
}
\prod_{s=t-\tau+1}^t\frac{\Lambda_s^{I_s}}{I_s!}
\end{aligned} \tag{eq:likelihood}
\]</span></p>
<p>To make use of the mathematical property of the conjugate prior of the Poisson distribution, we further assume a prior belief that <span class="math inline">\(R_{t,\tau}\)</span> is Gamma distributed with shape parameter <span class="math inline">\(\alpha\)</span> and rate parameter <span class="math inline">\(\beta\)</span> and hence by definition:</p>
<p><span class="math display">\[
\begin{aligned}
P(R_{t,\tau}) = \frac{\beta^\alpha}{\Gamma(\alpha)} R_{t,\tau}^{\alpha-1}e^{-\beta R_{t,\tau}}
\end{aligned}  \tag{eq:prior}
\]</span></p>
<p>We wish to determine the posterior probability of <span class="math inline">\(R_t\)</span> given the evidence <span class="math inline">\({I_0,\dots,I_{t},\omega}\)</span>, i.e. we wish to identify <span class="math inline">\(P(R_{t,\tau} | I_0,\dots,I_{t},\omega)\)</span>. We have a prior probability <span class="math inline">\(P(R_{t,\tau}\)</span>, and an expression for the likelihood of <span class="math inline">\(I_t-\tau+1, \dots, I_t\)</span> given <span class="math inline">\(I_0,\dots,I_{t-1}\)</span>, the infectivity profile <span class="math inline">\(\omega\)</span> and <span class="math inline">\(R_{t,\tau}\)</span>. To do this we uses Bayes theorem to restate the posterior probability of the relationship <span class="math inline">\(P(A \cup B) = P(A|B)P(B)\)</span> in two stages, firstly:</p>
<p><span class="math display">\[
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega)  &amp;= 
\frac{P(R_{t,\tau}, I_0,\dots,I_{t},\omega)}
{P(I_0,\dots,I_{t},\omega)}\\
\end{aligned}
\]</span></p>
<p>And secondly:</p>
<p><span class="math display">\[
\begin{aligned}
P(R_{t,\tau}, I_0,\dots,I_{t},\omega) &amp;=
P(R_{t,\tau}, I_{t-\tau+1}, \dots,I_{t}|I_0, \dots,I_{t-\tau},\omega)P(I_0, \dots,I_{t-\tau},\omega)
\\
\end{aligned}
\]</span></p>
<p>Substituting and re-organising:</p>
<p><span class="math display">\[
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega)
\frac{P(I_0,\dots,I_{t},\omega)}
{P(I_0, \dots,I_{t-\tau},\omega)}
&amp;= P(R_{t,\tau}, I_{t-\tau+1}, \dots,I_{t}|I_0, \dots,I_{t-\tau},\omega)
\\
\end{aligned}
\]</span></p>
<p>We have expressions for both the evidence <span class="math inline">\(P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau})\)</span> and prior belief <span class="math inline">\(P(R_{t,\tau})\)</span>, and we can relate these to the right hand side of the previous expression:</p>
<p><span class="math display">\[
\begin{aligned}
P(R_{t,\tau}, I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega) &amp;= 
\frac{
P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau})
P(R_{t,\tau})
}{
  P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega)
} \\
\end{aligned}
\]</span> And combining these last two expressions gives us:</p>
<p><span class="math display">\[
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega)
\frac{P(I_0,\dots,I_{t},\omega)}
{P(I_0, \dots,I_{t-\tau},\omega)}
&amp;=\frac{
P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau})
P(R_{t,\tau})
}{
  P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega)
} \\
\end{aligned}
\]</span></p>
<p>This includes components which are not conditional in any way on <span class="math inline">\(R_t\)</span>. Given <span class="math inline">\(I_0,\dots,I_{t},\omega\)</span> these components are constant:</p>
<p><span class="math display">\[
\frac{P(I_0, \dots,I_{t-\tau},\omega)}
{P(I_0,\dots,I_{t},\omega)P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega)} = K\\
\]</span></p>
<p>Which gives us the following expression for the posterior of <span class="math inline">\(R_t\)</span> given our prior belief and the evidence:</p>
<p><span class="math display">\[
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega)  &amp;= K 
P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau})
P(R_{t,\tau})
\end{aligned}
\]</span> Using the expressions for the likelihood <span class="math inline">\(\eqref{eq:likelihood}\)</span>, and the prior probability <span class="math inline">\(\eqref{eq:prior}\)</span> derived above we can express the :</p>
<p><span class="math display">\[
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega,\alpha,\beta)  &amp;= K
\Bigg(
  \prod_{s=t-\tau+1}^t\frac{(R_{t,\tau}\Lambda_t)^{I_s}e^{-R_{t,\tau}\Lambda_s}}{I_s!}
\Bigg)
\Bigg(
  \frac{\beta^\alpha}{\Gamma(\alpha)} R_{t,\tau}^{\alpha-1}e^{-\beta R_{t,\tau}}
\Bigg)
\\
&amp;=
KR_{t,\tau}^{\alpha+\sum_{s=t-\tau+1}^t I_s-1}e^{-R_{t,\tau}\big(\beta+\sum_{s=t-\tau+1}^t \Lambda_s\big)}
\Bigg(
  \prod_{s=t-\tau+1}^t\frac{\Lambda_s^{I_s}}{I_s!}
\Bigg)
\Bigg(
  \frac{\beta^\alpha}{\Gamma(\alpha)}
\Bigg)
\end{aligned}
\]</span></p>
<p>Which we noting has a form similar to a Gamma distribution with shape <span class="math inline">\(\alpha'\)</span> and scale <span class="math inline">\(\beta'\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\alpha' &amp;= \alpha+\sum_{s=t-\tau+1}^t I_s \\
\beta' &amp;= \beta+\sum_{s=t-\tau+1}^t \Lambda_s\\
\end{aligned}  \tag{eq:posterior}
\]</span></p>
<p>This leads us to the conclusion that the posterior distribution of <span class="math inline">\(R_t\)</span> is also Gamma distributed, with shape (<span class="math inline">\(\alpha'\)</span>) and rate (<span class="math inline">\(\beta'\)</span>) with a constant normalising factor which can be ignored:</p>
<p><span class="math display">\[
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega) &amp;=  
\frac{
  {\beta'}^{\alpha'}
}{
 \Gamma({\alpha'})
}
R_{t,\tau}^{{\alpha'}-1}e^{-R_{t,\tau}{\beta'}}
\Bigg[K\Bigg(
  \prod_{s=t-\tau+1}^t\frac{\Lambda_s^{I_s}}{I_s!}
\Bigg)
\Bigg(
  \frac{
    \Gamma(\alpha')\beta^\alpha
  }{
    \Gamma(\alpha){\beta'}^{\alpha'}
  }
\Bigg)
\Bigg]\\
R_{t,\tau} | I_0,\dots,I_{t},\omega &amp;\sim Gamma\Big(\alpha+\sum_{s=t-\tau+1}^t I_s, \beta+\sum_{s=t-\tau+1}^t \Lambda_s\Big)
\end{aligned}
\]</span></p>
<p>This final expression for the reproduction number explicitly integrates information from the last <span class="math inline">\(t \dots t-\tau+1\)</span> time points. However within the <span class="math inline">\(\Lambda_s\)</span> term from <span class="math inline">\(\eqref{eq:lambdaS}\)</span> there is also information stretching back further into the past, depending on the nature of <span class="math inline">\(\omega\)</span>. In reality the duration from an infector and an infectee in practice is limited, and for SARS-CoV-2 we think secondary infections are rare after 10 days. In this case if we consider <span class="math inline">\(\omega\)</span> to have a finite <span class="math inline">\(N_\omega\)</span> terms, then knowledge of the time series between <span class="math inline">\(I_{t-\tau-N_\omega} \dots I_t\)</span> is sufficient to make an estimate of <span class="math inline">\(R_{t,\tau}\)</span>.</p>
</div>
<div id="limitations" class="section level1">
<h1 class="hasAnchor">
<a href="#limitations" class="anchor"></a>Limitations</h1>
<p>Considering again the difference between the case based and the instantaneous reproduction number, it is a property of the instantaneous reproduction number that, in the face of a step change in the case based reproduction number, the instantaneous reproduction number will only fully account for that change when <span class="math inline">\(N_\omega\)</span> days have elapsed. With the method presented here the additional delay introduced by the windowing must be accounted for when relating the estimates of <span class="math inline">\(R_t\)</span> to exact points in time, and relating them to the case based reproduction number. It is also of note that it is difficult to incorporate anomalous or missing data into the method presented here as a single missing value invalidates the estimates over the next <span class="math inline">\(N_\omega+\tau\)</span> time points.</p>
<p>As a final observation, the coefficient of variation (<span class="math inline">\(\kappa\)</span>) of a gamma distribution is the reciprocal of the square root of the shape parameter, which for the <span class="math inline">\(R_t\)</span> estimate is give by <span class="math inline">\(\eqref{eq:posterior}\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\kappa &amp;= \frac{\text{sd}}{\text{mean}}\\
\kappa &amp;= \frac{\sqrt{\frac{\alpha}{\beta^2}}}{\frac{\alpha}{\beta}}\\
\kappa &amp;= \frac{1}{\sqrt{\alpha}}\\
\kappa_{R_t} &amp;= \frac{1}{\sqrt{\alpha+\sum_{s=t-\tau+1}^t I_s}}\\
\end{aligned}
\]</span></p>
<p>The form of <span class="math inline">\(\kappa_{R_t}\)</span> is highly influenced by the count of infections. When infection numbers are in the thousands per day, the coefficient of variation becomes small regardless of the prior parameterisation. This is independent of the infectivity profile and leads to very certain estimates of <span class="math inline">\(R_t\)</span> particularly when infection numbers are large for a sustained period of time. It is not clear whether this certainty is always appropriate. An inherent assumption that the observed infections (<span class="math inline">\(I_t\)</span>) are a true representation of the expected value of the infections (<span class="math inline">\(\overline{I_t}\)</span>), and that these are Poisson distributed is core to this method, and over-dispersion of the observed case counts is not adjusted for.</p>
<p>The method presented here represents an estimate over a time window where <span class="math inline">\(R_t\)</span> is assumed to be constant. When this is in fact not the case, and <span class="math inline">\(R_t\)</span> is changing rapidly, the violation of this assumption leads to a certain but rapidly changing estimate that does not reflect reality. Shortening the time window over which the estimate is made in this situation may help, but this may in turn lead to excessive variation in central estimates particularly in the case where there is a weekly cycle to observations.</p>
</div>
<div id="implementation-considerations" class="section level1">
<h1 class="hasAnchor">
<a href="#implementation-considerations" class="anchor"></a>Implementation considerations</h1>
<p>The reference implementation of this method is provided by the R package EpiEstim. This has a range of features and configuration. The main element of this are various ways to configure the infectivity profile, either as a parameterised probability distribution, which is then discretised, or directly as an empirical set of weights (<span class="math inline">\(\omega\)</span>). There is also the option to provide uncertainty around the infectivity profile either as uncertainty bounds on the distribution parameters, which are then sampled to produce a set of parameterised distributions, which are then in turn discretised, or to provide that infectivity profile uncertainty directly as a sequence of empirical distributions (<span class="math inline">\(\omega_a, \omega_b, \omega_c, \dots\)</span>). In either event the algorithm progresses using such a sequence of empirical distributions, each one of which representing one possible infectivity profile. The estimate of <span class="math inline">\(R_t\)</span> for all profiles (<span class="math inline">\(R^{profiles}\)</span>) is then calculated as a combination of all the possible estimates of <span class="math inline">\(R_t\)</span> given each of the infectivity profiles, and a size of window <span class="math inline">\(\tau\)</span>.</p>
<p><span class="math display">\[
R^{profiles}(t,\tau) = \{R_{t,\tau,\omega} : \omega \in \omega_a, \omega_b, \omega_c, \dots\}
\]</span></p>
<div id="prior-selection" class="section level2">
<h2 class="hasAnchor">
<a href="#prior-selection" class="anchor"></a>Prior selection</h2>
<p>The default implementation uses the same fixed prior gamma distribution for <span class="math inline">\(R_t\)</span> for all points in the time series. This is configurable but recommended to be set to a value (e.g. 5). Reversion to the prior <span class="math inline">\(R_t\)</span> when case incidence is low, for example at the start of the time series, means R at very low incidence may become biased towards the set prior value.</p>
<p>An alternative to this fixed prior, is to use an "informed" prior that assumes that estimates of <span class="math inline">\(R_t\)</span> are likely to be continuous in time, and uses previous posterior <span class="math inline">\(R_t\)</span> estimates to calculate priors for the next time point. The porevious time point posteriors are combined with a scale factor <span class="math inline">\(k\)</span> that increases the standard deviation of the prior distribution compared to the posterior of the previous time step, whilst keeping the mean constant. This essentially allows the prior at time <span class="math inline">\(t\)</span> to be the posterior at time <span class="math inline">\(t-1\)</span> plus a random walk, the variation of which is controlled by <span class="math inline">\(k\)</span>. By enforcing the continuity in time the aim is to stabilise noisy estimates of <span class="math inline">\(R_t\)</span> when incidence is low, however this strategy may worsen the over-precise estimates seen when case numbers are high.</p>
<p><span class="math display">\[
\begin{aligned}
E(R_{t,prior}) &amp;= E(R_{t-1,posterior}) \\
V(R_{t,prior}) &amp;= k^2V(R_{t-1,posterior}) \\
\alpha_{t,prior} &amp;= \frac{E(R_{t-1,posterior})^2}{k^2V(R_{t-1,posterior})} \\
\alpha_{t,prior} &amp;= \frac{\alpha_{t-1,posterior}^2}{\beta_{t-1,posterior}^2}\frac{\beta_{t-1,posterior}^2}{k^2\alpha_{t-1,posterior})}\\
\alpha_{t,prior} &amp;= \frac{\alpha_{t-1,posterior}}{k^2} \\
\beta_{t,prior} &amp;= \frac{E(R_{t-1,posterior})}{k^2V(R_{t-1,posterior})} \\
\beta_{t,prior} &amp;= \frac{\alpha_{t-1,posterior}}{\beta_{t-1,posterior}}\frac{\beta_{t-1,posterior}^2}{k^2\alpha_{t-1,posterior})}\\
\beta_{t,prior} &amp;= \frac{\beta_{t-1,posterior}}{k^2}\\
R_{t,prior} &amp;\sim Gamma\big(\frac{\alpha_{t-1,posterior}}{k^2}, \frac{\beta_{t-1,posterior}}{k^2}\big)
\end{aligned}
\]</span></p>
</div>
<div id="windowing-strategy-and-posterior-estimate-selection" class="section level2">
<h2 class="hasAnchor">
<a href="#windowing-strategy-and-posterior-estimate-selection" class="anchor"></a>Windowing strategy and posterior estimate selection</h2>
<p>In appendix A we observed the selection of a windowing parameter may have a significant effect on the bias variance trade-off, and selecting a single window may produces estimates that may either be too precise or too noisy. Picking the right value is also constrained by the observation that in the face of weekly periodicity of case incidence, <span class="math inline">\(R_t\)</span> estimates may over-fit the data when windows are too short.</p>
<p>It is computationally efficient to calculate arrange of windows at the same time, and with all windows available we open up some options to select the best posterior in a different way. The first possibility is to adopt an adaptive strategy allows window selection to be determined by the case incidence within the window (<span class="math inline">\(\sum I_t\)</span>). By selecting longer windows where case numbers are small we both improve the certainty of the estimate, and reduce its noise, and when case numbers are high we reduce the window size to allow more rapid adaption to changing <span class="math inline">\(R_t\)</span>, with less risk of over-fitting. This strategy is summarised as follows where <span class="math inline">\(R^{adaptive}\)</span> is the set of estimates where the window size <span class="math inline">\(\tau\)</span> is the smallest possible value that encompasses enough data.</p>
<p><span class="math display">\[
R^{adaptive}(t, \tau_{min}, \tau_{max}, I_{min}) = \{R^{profiles}(t, \tau) : \tau =min\Big(\tau_{max}\Big|\tau_{min} \leq \tau; I_{min} \leq \sum_{s=t-\tau+1}^t I_s\Big)\}
\]</span></p>
<p>In the validation study we observed that the EpiEstim reference implementation with 14 day window produces a lagged, over-precise estimate. The degree of lag determines the overall accuracy of the method when <span class="math inline">\(R_t\)</span> is rapidly changing. This happens because the assumption that <span class="math inline">\(R_t\)</span> is constant over a window period <span class="math inline">\(\tau\)</span> is violated. The precision of the <span class="math inline">\(R_t\)</span> estimate is unwarranted in this situation. Once we have a range of windows calculated we may address this problem. Firstly, with a range of different time windows for any given time point, there are a set of estimates of <span class="math inline">\(R_t\)</span> that are equally valid, and which capture different assumptions about the length of time over which <span class="math inline">\(R_t\)</span> is constant. Secondly, if the time point in consideration is <span class="math inline">\(s\)</span> days in the past, there are also estimates from later time points, where <span class="math inline">\(s \leq t+\tau\)</span> that are also relevant to time <span class="math inline">\(t\)</span>. In this case the <span class="math inline">\(R_s,\tau\)</span> estimate assumes the reproduction number is constant over the time period <span class="math inline">\(s-\tau-1 \dots s\)</span>. If we consider allowing <span class="math inline">\(\tau\)</span> to vary between two limits (<span class="math inline">\(\tau_{min} \leq \tau \leq \tau_{max}\)</span>) then we can describe the set of all estimates of effective <span class="math inline">\(R_t\)</span> that are relevant to a single time point as <span class="math inline">\(R_{t,all}\)</span>:</p>
<p><span class="math display">\[
R^{all}(t,\tau_{min}, \tau_{max}) = \{R^{profiles}(s,\tau) : \tau_{min} \leq \tau \leq \tau_{max} ; t \leq s \leq t+\tau\}
\]</span></p>
<p>This is better explained visually and figure B1 demonstrates at time <span class="math inline">\(s=10\)</span> that estimates where <span class="math inline">\(10 \leq s+\tau \leq 16\)</span> are all of relevance to the time point <span class="math inline">\(s\)</span>. All possible combinations of window and future time point <span class="math inline">\(R_t\)</span> estimates that are relevant to a specific point in time are shown. Each red point represents an <span class="math inline">\(R_t\)</span> estimate that is based on some assumption about the reproduction number on day 10, and all of these estimates may be combined to produce a final <span class="math inline">\(R_t\)</span> estimate for day 10. This set of estimates provides a broader set of assumptions than a single window can provide and therefore may reduce the unwanted over-precision of estimates when <span class="math inline">\(R_t\)</span> is changing rapidly.</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/estimation-windows-2022-01-28.png" width="885"></p>
<p><em>Figure B1: A graphical representation of the information involved in estimates of <span class="math inline">\(R_t\)</span> using the renewal equation method with different length windows (y-axis). The highlighted estimates (red dots) all use estimation windows that span the 10th day and during each of these windows there is an assumption of constant <span class="math inline">\(R_t\)</span>. In situations where the true <span class="math inline">\(R_t\)</span> is dynamic, combining these estimates may reflect the overall uncertainty.</em></p>
</div>
<div id="combining-posterior-estimates" class="section level2">
<h2 class="hasAnchor">
<a href="#combining-posterior-estimates" class="anchor"></a>Combining posterior estimates</h2>
<p>In all the estimates thus far (<span class="math inline">\(R^{profiles}\)</span>,<span class="math inline">\(R^{adaptive}\)</span>, and <span class="math inline">\(R^{all}\)</span>) the estimate of <span class="math inline">\(R_t\)</span> take the form of a set of posterior gamma distributions for each time point. This is a result of the fact that there are multiple infection profiles, expressing uncertainty, or there are multiple windows over which the estimate is calculated, or there are multiple days over which the estimates are collected. These estimates must be combined, and there are different possible strategies for doing this.</p>
<p>In the reference implementation, multiple estimates resulting from multiple infection profiles, are combined by constructing an empirical distribution from Monte-Carlo random sampling of the posterior Gamma distributions of all estimates. Quantiles are estimated from this empirical distribution. This is not deterministic, and for a reasonable degree of accuracy is computationally expensive.</p>
<p>When we consider that the only information we need to get from the mixture of posterior distributions is a set of quantiles, an alternative strategy therefore is to construct a mixture distribution from the set of posteriors and solve it numerically for the quantiles. Given random sampling does the same process in an un-targeted way this is actually less overall effort and provides a deterministic result.</p>
<p>The posterior estimates should be similar to one another. A reasonable approximation therefore is to consider the mixture distribution as another Gamma distribution with first and second moments matching those of the mixture distribution. This is quick to calculate and allows us to rapidly combine the potentially large number of estimates that arise from the multiplicative combinations of infection profiles, variable window length and variable day of estimate. The quality of this estimate will depend on how different the distributions are from each other, but this again produces a deterministic result. The parameterisation of the estimated gamma distribution is expressed below in terms of shape (<span class="math inline">\(\alpha\)</span>) and rate (<span class="math inline">\(\beta\)</span>) parameters, composed of a mixture of gamma distributions (<span class="math inline">\(\sim Gamma(\alpha_i,\beta_i)\)</span>) from the posterior estimates.</p>
<p><span class="math display">\[ 
\begin{aligned}
E[X] = \mu = \frac{\alpha}{\beta} &amp;= \frac{1}{n} \sum_1^n  \mu_i = \frac{1}{n} \sum_1^n  \frac{\alpha_i}{\beta_i} \\
E[(X-\mu)^2] = \sigma^2 = \frac{\alpha}{\beta^2} &amp;= E[X^2]-\mu^2 \\
&amp;= \frac{1}{n} \Big(\sum_1^n E[X_i^2]\Big) - \mu^2 \\
&amp;= \frac{1}{n} \Big(\sum_1^n \sigma_i^2+\mu_i^2\Big) - \mu^2 \\
&amp;= \frac{1}{n} \Big(\sum_1^n \frac{\alpha_i}{\beta_i^2}+\big(\frac{\alpha_i}{\beta_i}\big)^2 \Big) - \big(\frac{1}{n} \sum_1^n\frac{\alpha_i}{\beta_i}\Big)^2 \\
&amp;= \frac{1}{n} \Big(\sum_1^n \frac{\alpha_i}{\beta_i^2}+\frac{\alpha_i^2}{\beta_i^2} - \frac{1}{n} \frac{\alpha_i^2}{\beta_i^2}\Big) \\
&amp;= \frac{1}{n} \Big(\sum_1^n \frac{\alpha_i+\frac{n-1}{n}\alpha_i^2}{\beta_i^2}\Big) \\
\alpha = \frac{\mu^2}{\sigma^2} &amp;= \frac{1}{n} \frac{\Big(\sum_1^n\frac{\alpha_i}{\beta_i}\Big)^2}{\Big(\sum_1^n \frac{\alpha_i+\frac{n-1}{n}\alpha_i^2}{\beta_i^2}\Big)} \\
\beta = \frac{\mu}{\sigma^2} &amp;= \frac{\Big(\sum_1^n\frac{\alpha_i}{\beta_i}\Big)}{\Big(\sum_1^n \frac{\alpha_i+\frac{n-1}{n}\alpha_i^2}{\beta_i^2}\Big)}
\end{aligned}
\]</span></p>
<p>In all the strategies described above there is the potential to weight specific estimates more than others. As each infectivity profile is taken to be equally likely this only make sense when combining estimates made over many time windows, and such a weighing may be based on a function of the size of the window, or potentially a function of the number of cases observed within the window. This is beyond the scope of this description.</p>
</div>
</div>
<div id="validation-and-comparison" class="section level1">
<h1 class="hasAnchor">
<a href="#validation-and-comparison" class="anchor"></a>Validation and comparison</h1>
<p>The implementation of the renewal equation method has options for informed prior selection, broader posterior selection, and different methods for combining the posteriors. To evaluate the impact of these different implementation strategies we compare them using the methods described in appendix A in the next section. In all comparisons we use the validation data set described in appendix A with a fixed infectivity profile distribution based on a discretised Gamma distribution with mean of 5 and standard deviation of 4.</p>
<div id="informed-prior-selection" class="section level2">
<h2 class="hasAnchor">
<a href="#informed-prior-selection" class="anchor"></a>Informed prior selection</h2>
<p>In this comparison we are looking at the performance change resulting from changing the prior selection strategy from a fixed prior to that of an informed prior. Our baseline reference methodology is the default EpiEstim configuration including a fixed prior R_t with mean of 1.2 and standard deviation of 4, and with <span class="math inline">\(R_t\)</span> estimates calculated over a 7 days period. We vary the configuration by adopting an informed prior strategy with a step size factor <span class="math inline">\(\kappa=1.25\)</span> and the same 7 day window, and secondly with <span class="math inline">\(\kappa=1.125\)</span> and a smaller 4 day window.</p>
<p>The qualitative result of these changes is shown in figure B1, which demonstrates a modest reduction in high frequency noise, particularly in time periods where the incidence is low, for the same time period, and that this is retained when we shorten the time window from 7 to 4 days, if we also reduce the step size factor.</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/qualitative-prior-selection-2022-01-28.png" width="885"></p>
<p><em>Figure B1: qualitative estimates of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing 3 methods that vary in their prior selection process</em></p>
<p>As the use of an informed prior constrains the rate of change of the <span class="math inline">\(R_t\)</span> estimate in the face of sudden changes in the true value, it is expected that smaller values of <span class="math inline">\(k\)</span>, the random walk step factor, result in estimates with more stiffness in time, and hence an increase in the delay. This is borne out by Figure B2 in which smaller step size values result in more estimate delay. This partly defeats the purpose of introducing the informed prior as a way to shorten the window needed and hence improve responsiveness to step changes in <span class="math inline">\(R_t\)</span>.</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/lag-prior-selection-2022-01-28.png" width="885"></p>
<p><em>Figure B2: time delay analysis of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing 3 methods that vary in their prior selection process</em></p>
<p>A quantitative comparison of the 3 methods in Figure B3 and Table B1 reveals that the informed prior does improve the estimate against the validation set when assessed by the continuous rank probability score (CRPS), but as predicted the informed prior also worsens the over-precision of the estimator, with I shaped violin plots, and increasing quantile deviation scores. Although not demonstrated here we expect the improvement in CRPS to be most noticeable for the smoothly varying validation scenarios rather than step changes which we think it will perform less well on.</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/error-summary-prior-selection-2022-01-28.png" width="885"></p>
<p><em>Figure B3: quantitative analysis of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing 3 methods that vary in their prior selection process</em></p>
<p><em>Table B1: summary of quantitative analysis of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing 3 methods that vary in their prior selection process</em></p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/error-summary-prior-selection-table-2022-01-28.png" width="885"></p>
</div>
<div id="posterior-selection-" class="section level2">
<h2 class="hasAnchor">
<a href="#posterior-selection-" class="anchor"></a>Posterior selection.</h2>
<p>In this comparison we are looking at the performance change resulting from changing the posterior selection strategy.Our baseline reference methodology is the default EpiEstim configuration including a fixed prior R_t with mean of 1.2 and standard deviation of 4. We select posterior <span class="math inline">\(R_t\)</span> estimates that are calculated over a 7 days period. We vary the configuration by firstly allowing the posterior to be automatically selected to ensure a minimum number of cases (in this instance 100) in the estimation window (down to a minimum of 4 days). This is the adaptive window described above.</p>
<p>The second comparison is against the combined posterior estimate of all windows that span a given time point, and described above. The multiple estimates of <span class="math inline">\(R_t\)</span> for the different window sizes, and start and end dates, obtained this way are combined by empirical re-sampling as in the original EpiEstim implementation.</p>
<p>The qualitative result of these changes is shown in figure B4, which demonstrates the adaptive window results in excess high frequency noise in the scenario with weekend variation shown, compared to the reference implementation. This is an indication of over-fitting as a result of the selection of short (&lt;7 day) windows. The "All windows" strategy on the other hand produces a stable estimate with broader confidence intervals which aligns closely to the true value.</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/qualitative-posterior-selection-2022-01-28.png" width="885"></p>
<p><em>Figure B4: qualitative estimates of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing 3 methods that vary in their posterior selection process</em></p>
<p>The different posterior selection strategies involve integrating information from different sized windows, this in turn affects the degree of time delay within the estimate as shown in Figure B5, with the reference implementation having the most delay, whereas the "all windows" strategy includes estimates from short and long windows and therefore responds relatively quickly to change. It must be pointed out that the true value of the reproduction number is calculated using the methods of Wallinga et al (2007) <span class="citation">[@wallingaHowGenerationIntervals2007]</span> which produces a different type of reproduction number to the instantaneous reproduction number produced by the renewal equation methods presented here.</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/lag-posterior-selection-2022-01-28.png" width="885"></p>
<p><em>Figure B5: time delay analysis of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing 3 methods that vary in their posterior selection process</em></p>
<p>The purpose of investigating the posterior selection was to reduce the over-precision, and improve calibration of the estimates without compromising the overall performance. In Figure B6 and Table B2 we can see that the "All windows" strategy is well calibrated, successful in reducing over precision, with a tendency towards excessive uncertainty, seen in the O shaped quantile density plot, and negative quantive deviation score, and that overall it performs equally well as the reference implementation in terms of CPRS.</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/error-summary-posterior-selection-2022-01-28.png" width="885"></p>
<p><em>Figure B6: quantitative analysis of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing 3 methods that vary in their posterior selection process</em></p>
<p><em>Table B2: summary of quantitative analysis of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing 3 methods that vary in their posterior selection process</em></p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/error-summary-posterior-selection-table-2022-01-28.png" width="885"></p>
</div>
<div id="combining-posteriors" class="section level2">
<h2 class="hasAnchor">
<a href="#combining-posteriors" class="anchor"></a>Combining posteriors</h2>
<p>For this comparison we further examine the "All windows" strategy from above, which combines a number of different <span class="math inline">\(R_t\)</span> posterior estimates, by varying the method in which these are combined. The original EpiEstim implementation uses random sampling to combine posteriors, and we compare this to both a formal estimation of the quantiles of a mixture of posterior estimates, and an approximation of the mixture using the method of matching moments described above. The qualitative analysis in figure B7 suggests this change has very limited effect on the estimate quality, and in table B3 this is confirmed with the quantitative metrics. As the mixture approximation is far less computationally expensive than the other methods it seems this is best approach.</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/qualitative-posterior-combination-2022-01-28.png" width="885"></p>
<p><em>Figure B7: qualitative estimates of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing 3 methods that vary in their posterior combination process</em></p>
<p><em>Table B3: summary of quantitative analysis of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing 3 methods that vary in their posterior combination process</em></p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/error-summary-posterior-combination-table-2022-01-28.png" width="885"></p>
</div>
</div>
<div id="overall-combination" class="section level1">
<h1 class="hasAnchor">
<a href="#overall-combination" class="anchor"></a>Overall combination</h1>
<p>With the step-by-step analysis above we can make informed decision about how to best go about estimating <span class="math inline">\(R_t\)</span> using the renewal equation method to address some of its limitations. Estimating <span class="math inline">\(R_t\)</span> by combining all the estimation windows available, into a single Gamma distribution approximating the mixture of posteriors, when combined with an informed prior based on a posterior estimates from previous time-steps, with a moderate choice for the step size factor, has potential to perform well as an estimator. This is tested below, with the step size factor of 1.25. The qualitative results of this comparison are in figure B8, which shows the improved method producing stable, and seemingly accurate estimates of <span class="math inline">\(R_t\)</span>.</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/qualitative-reference-versus-improved-2022-01-28.png" width="885"></p>
<p><em>Figure B8: qualitative estimates of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing the reference implementation to a proposed improved method</em></p>
<p>As before the introduction of a informed prior introduces hysteresis and delay into the estimates compared with the fixed prior (shown in figure B5), but this delay is still less than the reference implementation.</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/lag-reference-versus-improved-2022-01-28.png" width="885"></p>
<p><em>Figure B10: time delay analysis of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing the reference implementation to a proposed improved method</em></p>
<p>A qualitative analysis in Figure B11 and Table B4 demonstrates the improved estimators are indeed better calibrated than the reference implementation, and perform better on the CPRS score. They have a more uniform quantile density plot and a quantile deviation score very close to 0. This suggests we have been successful in improving the estimate quality.</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/error-summary-reference-versus-improved-2022-01-28.png" width="885"></p>
<p><em>Figure B11: quantitative analysis of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing the reference implementation to a proposed improved method</em></p>
<p><em>Table B4: summary of quantitative analysis of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing the reference implementation to a proposed improved method</em></p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/error-summary-reference-versus-improved-table-2022-01-28.png" width="885"></p>
<p>For completeness we examine what drives the improved estimator's performance, and in figure B11 we see notable improvements in calibration occur particularly in the high incidence scenarios (panel G) and the reduction in over-precision is again most marked in the high incidence scenarios (panel K).</p>
<p><img src="../../../../../../../home/terminological/Dropbox/sarscov2/r-estimation-methodology/error-breakdown-reference-versus-improved-2022-01-28.png" width="885"></p>
<p><em>Figure B11: detailed breakdown of quantitative analysis of <span class="math inline">\(R_t\)</span> (black) against simulated (red) comparing the reference implementation to a proposed improved method</em></p>
</div>
<div id="summary" class="section level1">
<h1 class="hasAnchor">
<a href="#summary" class="anchor"></a>Summary</h1>
<p>In this appendix we have described the detail of the renewal equation method for estimating <span class="math inline">\(R_t\)</span>. We find a few limitations of the method, and particularly the over-precise estimates that can occur when case incidence is high, and the limitations resulting from the assumption that <span class="math inline">\(R_t\)</span> is constant over a window of time. We undertook a re-implementation of the algorithm in Java and used this to explore the possibilities of combining estimates with different window size assumptions and with different start and end dates, which provides us with a broader set of estimates that better reflects uncertainty. Our implementation also allows for the imposition of a constraint of continuity on the time-series of the estimates, which allows for more precise estimates when case numbers are small. Combined together these alterations produce a novel method for estimating the reproduction number that is better calibrated, and performs well under detailed validation.</p>
</div>
<div id="references" class="section level1">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs">

</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Rob Challen, terminological.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
