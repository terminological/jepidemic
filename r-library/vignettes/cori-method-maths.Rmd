---
title: "Appendix A - Cori method"
author: "Rob Challen"
date: '`r format(Sys.Date(), "%d-%m-%Y")`'
output: 
  pdf_document :
    fig_caption: yes
header-includes:
 \usepackage{float}
 \usepackage{mathtools}
 \usepackage{amsmath}
 \floatplacement{figure}{H}    
 \DeclareRobustCommand{\[}{\begin{equation*}}
 \DeclareRobustCommand{\]}{\end{equation*}}
 \newcounter{tagno}
 \setcounter{tagno}{0}
 \let\amsmathtag\tag
 \renewcommand{\tag}[1]{\amsmathtag{\thetagno} \label{#1} \stepcounter{tagno}}
knit: (function(inputFile, encoding,...) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "~/Dropbox/sarscov2/r-estimation-methodology", output_file=paste0('cori-method-maths-',Sys.Date(),'.pdf')) })
fig_width: 7
fig_height: 5
out.width: "100%"
bibliography: jepidemic.bib
csl: jepidemic.csl
vignette: >
  %\VignetteIndexEntry{Cori method}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Review of the Cori method

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  error = TRUE
)

here::i_am("vignettes/cori-method-validation.Rmd")
source(here::here("vignettes/common-setup.R"))


```

This appendix provides a detailed review of the methodology for estimating the effective reproduction number presented by Cori et al. [CITE], and which supported much of the analysis contained in this thesis. 
[TODO: restructure] 
The infectivity profile is another probability distribution. Most often represented in discrete form $\omega_1, \omega_2, \dots, \omega_s$, that defines the likelihood that a case infected at time $t$ resulted from a case infected between the times $t-s$ and $t-s+1$. This definition implies that $\omega_{s \leq 0} = 0$ as that would apply to secondary infections resulting from primary infections in the future, and that the discrete time measure $s$ here represents the upper bound of the equivalent continuous unit time interval, rather than, for example, the middle of the interval.

If we assume $I_0, I_1, \dots, I_t$ is a time series of infection counts, assumed to be drawn from some discrete probability distribution with expected value $\overline{I_t}$ 

We can alternatively define the backward-looking effective reproduction number $R_t^i$ as the inverse ratio of the number of primary infections that cause the secondary infections observed at time $t$, this is known as the instantaneous reproduction number, $R_t^i$. In an evolving epidemic the instantaneous reproduction number is able to be calculated using data that has already been observed and is hence the more useful quantity. The rest of this summary considers the instantaneous version of the effective reproduction number, which we refer to as the reproduction number or $R_t$.

$$
\begin{aligned}
R_t^i &= \frac{\overline{I_t}}{\sum_{s=1}^t \overline{I_{t-s}}\omega_s} \\
\end{aligned} 
\tag{eq:rt}
$$

With the definitions above we consider the number of new cases on a day $I_t$, which is the convolution of the number of cases observed in previous time points by the infectivity profile, scaled by the reproduction number, and defining the quantity $\Lambda$ as the number of primary cases that resulted in a secondary case at time $t$, and is the denominator in $\eqref{eq:rt}$. This definition disregards the possible role of co-infection, assuming secondary cases result from one, and only one, infection. 

<!-- 
N.B. thinking about weighing of the observations or adjusting for weekly periodicity. 
Don't think it can be done that easily but Lambda would be the place to incorporate it 
I think. It would be nice Lambda is possible to infer in the face of missing data?
-->

$$
\begin{aligned}
\Lambda_t &= \sum_{s=1}^t I_{t-s}\omega_s \\
E[I_t| I_0,\dots,I_{t-1},\omega,R_t] &= R_t\Lambda_t 
\end{aligned}
\tag{eq:lambdaS}
$$
We also assume that as a series of counts the case incidence can be represented as a Poisson distribution, $I_t \sim Pois(\lambda_t)$ and therefore $\lambda_t = \overline{I_t}$. Given the infectivity profile distribution $\omega$, the number of cases we expect to see on a given day, is given by the Poisson distribution probability density function:

$$
\begin{aligned} 
P(I_t) &= \frac{\lambda_t^{I_t} e^{-\lambda_t}}{I_t!} \\
\lambda_t &\approx E[I_t| I_0,\dots,I_{t-1},\omega,R_t]\\
P(I_t | I_0,\dots,I_{t-1},\omega,R_t) &= \frac{(R_t\Lambda_t)^{I_t}e^{-R_t\Lambda_t}}{I_t!} 
\end{aligned} \tag{eq:probIt}
$$
 
We are interested in producing estimates of the reproduction number that are conditioned on the data we have available. To do this we assume $R_t$ is constant over a short time period of $\tau$ days prior to and including the date of the estimate $[t-\tau+1;t]$ (and defined as $R_{t,\tau}$). 

As an aside, we note the following relationship:

$$
\begin{aligned}
 P(A_3 | A_2,A_1)  \times P(A_2 | A_1)  &= \\
 &= \frac{P(A_3,A_2,A_1)}{P(A_2,A_1)}  \times  \frac{P(A_2 , A_1)}{P(A_1)}\\
 &= \frac{P(A_3,A_2,A_1)}{P(A_1)}\\
 &= P(A_3,A_2|A_1)
\end{aligned}
$$
We use this to consider the combined probability of observing $I_{t-\tau+1} \dots I_t$, given the other information available to us:

$$
\begin{aligned}
P(I_t | I_0,\dots,I_{t-1},\omega,R_{t,\tau}) &\times \\
P(I_{t-1} | I_0,\dots,I_{t-2},\omega,R_{t,\tau})  &\times  \\
P(I_{t-2} | I_0,\dots,I_{t-3},\omega,R_{t,\tau})  &\times  \\
\dots &\\
P(I_{t-\tau+1} | I_0,\dots,I_{t-\tau-1},\omega,R_{t,\tau})& \\
&= P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau})
\end{aligned}
$$
Which we can express using $\eqref{eq:probIt}$ as the product of the components:

$$
\begin{aligned}
P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau}) &= \prod_{s=t-\tau+1}^t\frac{(R_{t,\tau}\Lambda_s)^{I_s}e^{-R_{t,\tau}\Lambda_s}}{I_s!}
\\
&=
R_{t,\tau}^{\sum_{s=t-\tau+1}^t I_s}
e^{
  -R_{t,\tau}
  \big(
    \sum_{s=t-\tau+1}^t \Lambda_s
  \big)
}
\prod_{s=t-\tau+1}^t\frac{\Lambda_s^{I_s}}{I_s!}
\end{aligned} \tag{eq:likelihood}
$$
To make use of the mathematical property of the conjugate prior of the Poisson distribution, we further assume a prior belief that $R_{t,\tau}$ is Gamma distributed with shape parameter $\alpha$ and rate parameter $\beta$ and hence by definition:

$$
\begin{aligned}
P(R_{t,\tau}) = \frac{\beta^\alpha}{\Gamma(\alpha)} R_{t,\tau}^{\alpha-1}e^{-\beta R_{t,\tau}}
\end{aligned}  \tag{eq:prior}
$$

We wish to determine the posterior probability of $R_t$ given the evidence ${I_0,\dots,I_{t},\omega,\alpha,\beta}$, i.e. we wish to identify $P(R_{t,\tau} | I_0,\dots,I_{t},\omega,\alpha,\beta)$. We have a prior probability $P(R_{t,\tau}$, and an expression for the likelihood of $I_t-\tau+1, \dots, I_t$ given $I_0,\dots,I_{t-1}$, the infectivity profile $\omega$ and $R_{t,\tau}$. To do this we uses Bayes theorem to restate the posterior probability of the relationship $P(A \cup B) = P(A|B)P(B)$ in two stages, firstly:

$$
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega)  &= 
\frac{P(R_{t,\tau}, I_0,\dots,I_{t},\omega)}
{P(I_0,\dots,I_{t},\omega)}\\
\end{aligned}
$$

And secondly:

$$
\begin{aligned}
P(R_{t,\tau}, I_0,\dots,I_{t},\omega) &=
P(R_{t,\tau}, I_{t-\tau+1}, \dots,I_{t}|I_0, \dots,I_{t-\tau},\omega)P(I_0, \dots,I_{t-\tau},\omega)
\\
\end{aligned}
$$

Substituting and re-organising:

$$
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega)
\frac{P(I_0,\dots,I_{t},\omega)}
{P(I_0, \dots,I_{t-\tau},\omega)}
&= P(R_{t,\tau}, I_{t-\tau+1}, \dots,I_{t}|I_0, \dots,I_{t-\tau},\omega)
\\
\end{aligned}
$$

We have evidence $P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau})$ and prior belief $P(R_{t,\tau})$, and we can relate these to the right hand side of the previous expression:

$$
\begin{aligned}
P(R_{t,\tau}, I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega) &= 
\frac{
P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau})
P(R_{t,\tau})
}{
  P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega)
} \\
\end{aligned}
$$
And combining these last two expressions gives us:

$$
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega)
\frac{P(I_0,\dots,I_{t},\omega)}
{P(I_0, \dots,I_{t-\tau},\omega)}
&=\frac{
P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau})
P(R_{t,\tau})
}{
  P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega)
} \\
\end{aligned}
$$

This includes components which are not conditional in any way on $R_t$. Given $I_0,\dots,I_{t},\omega$ these components are constant:

$$
\frac{P(I_0, \dots,I_{t-\tau},\omega)}
{P(I_0,\dots,I_{t},\omega)P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega)} = K\\
$$

Which gives us the following expression for the posterior of $R_t$ given our prior belief and the evidence:

$$
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega)  &= K 
P(I_{t-\tau+1}, \dots,I_t | I_0,\dots,I_{t-\tau},\omega,R_{t,\tau})
P(R_{t,\tau})
\end{aligned}
$$
Using the expressions for the likelihood $\eqref{eq:likelihood}$, and the prior probability $\eqref{eq:prior}$ derived above we can express the :

$$
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega,\alpha,\beta)  &= K
\Bigg(
  \prod_{s=t-\tau+1}^t\frac{(R_{t,\tau}\Lambda_t)^{I_s}e^{-R_{t,\tau}\Lambda_s}}{I_s!}
\Bigg)
\Bigg(
  \frac{\beta^\alpha}{\Gamma(\alpha)} R_{t,\tau}^{\alpha-1}e^{-\beta R_{t,\tau}}
\Bigg)
\\
&=
KR_{t,\tau}^{\alpha+\sum_{s=t-\tau+1}^t I_s-1}e^{-R_{t,\tau}\big(\beta+\sum_{s=t-\tau+1}^t \Lambda_s\big)}
\Bigg(
  \prod_{s=t-\tau+1}^t\frac{\Lambda_s^{I_s}}{I_s!}
\Bigg)
\Bigg(
  \frac{\beta^\alpha}{\Gamma(\alpha)}
\Bigg)
\end{aligned}
$$

Which we noting has a form similar to a gamma with shape $\alpha'$ and scale $\beta'$:

$$
\begin{aligned}
\alpha' &= \alpha+\sum_{s=t-\tau+1}^t I_s \\
\beta' &= \beta+\sum_{s=t-\tau+1}^t \Lambda_s\\
\end{aligned}  \tag{eq:posterior}
$$

Leads us to the conclusion that the posterior distribution of $R_t$ is Gamma distributed, with shape ($\alpha'$) and rate  ($\beta'$) with a constant normalising factor which can be ignored:

$$
\begin{aligned}
P(R_{t,\tau} | I_0,\dots,I_{t},\omega) &=  
\frac{
  {\beta'}^{\alpha'}
}{
 \Gamma({\alpha'})
}
R_{t,\tau}^{{\alpha'}-1}e^{-R_{t,\tau}{\beta'}}
\Bigg[K\Bigg(
  \prod_{s=t-\tau+1}^t\frac{\Lambda_s^{I_s}}{I_s!}
\Bigg)
\Bigg(
  \frac{
    \Gamma(\alpha')\beta^\alpha
  }{
    \Gamma(\alpha){\beta'}^{\alpha'}
  }
\Bigg)
\Bigg]\\
R_{t,\tau} | I_0,\dots,I_{t},\omega &\sim Gamma\Big(\alpha+\sum_{s=t-\tau+1}^t I_s, \beta+\sum_{s=t-\tau+1}^t \Lambda_s\Big)
\end{aligned}
$$

This final expression for the reproduction number explicitly integrates information from the last $t \dots t-\tau+1$ time points. However within the $\Lambda_s$ term from $\eqref{eq:lambdaS}$ there is also information stretching back further into the past, depending on the nature of $\omega$. In reality the duration from an infector and an infectee in practice is limited, and for Sars-COV-2 we think secondary infections are rare after 10 days. In this case if we consider $\omega$ to have a finite $N_\omega$ terms, then knowledge of the time series between $I_{t-\tau-N_\omega} \dots I_t$ is sufficient to make an estimate of $R_{t,\tau}$. 

Considering again the difference between the case based and the instantaneous reproduction number, it is a property of the instantaneous reproduction number that, in the face of a step change in the case based reproduction number, the instantaneous reproduction number will only fully account for that change when $N_\omega$ days have elapsed. With the method presented here the additional delay introduced by the windowing must be accounted for when relating the estimates of $R_t$ to exact points in time, and relating them to the case based reproduction number. It is also of note that it is difficult to incorporate anomalous or missing data into the method presented here as a single missing value invalidates the estimates over the next $N_\omega+\tau$ time points.

As a final observation, the coefficient of variation ($\kappa$) of a gamma distribution is the reciprocal of the square root of the shape parameter, which for the $R_t$ estimate is give by $\eqref{eq:posterior}$:

$$
\begin{aligned}
\kappa &= \frac{\text{sd}}{\text{mean}}\\
\kappa &= \frac{\sqrt{\frac{\alpha}{\beta^2}}}{\frac{\alpha}{\beta}}\\
\kappa &= \frac{1}{\sqrt{\alpha}}\\
\kappa_{R_t} &= \frac{1}{\sqrt{\alpha+\sum_{s=t-\tau+1}^t I_s}}\\
\end{aligned}
$$
The form of $\kappa_{R_t}$ is highly influenced by the count of infections. When infection numbers are in the thousands per day, the coefficient of variation becomes small regardless of the prior parameterisation. This is independent of the infectivity profile and leads to very certain estimates of $R_t$ particularly when infection numbers are large for a sustained period of time. It is not clear whether this certainty is completely appropriate and the assumption that the observed infections ($I_t$) are a true representation of the expected value of the infections ($\overline{I_t}$) may be in part the cause. 

The method presented here represents an estimate over a time window where $R_t$ is assumed to be constant. When this is in fact not the case, and $R_t$ is changing rapidly, the violation of this assumption leads to a certain but rapidly changing estimate that does not reflect reality. Shortening the time window over which the estimate is made in this situation may help, but this may in turn lead to excessive variation in central estimates particularly in the case where there is a weekly cycle to observations.

# Implementation considerations

The reference implementation of this method is provided by the R package EpiEstim. This has a range of features and configuration. The main element of this are various ways to configure the infectivity profile, either as a parameterised probability distribution, which is then discretised, or directly as an empirical set of weights ($\omega$). There is also the option to provide uncertainty around the infectivity profile either as uncertainty bounds on the distribution parameters, which are then sampled to produce a set of parameterised distributions, which are then in turn discretised, or directly as a sequence of empirical distributions ($\omega_a, \omega_b, \omega_c, \dots$). In either event the algorithm progresses using such a sequence of empirical weights each one of which represents one possible infectivity profile. The estimate of $R_t$ for all profiles ($R^{profiles}$) is then calculated as a combination of all the possible estimates of $R_t$ given each of the infectivity profiles, and a size of window $\tau$.

$$
R^{profiles}(t,\tau) = \{R_{t,\tau,\omega} : \omega \in \omega_a, \omega_b, \omega_c, \dots\}
$$

We saw in the validation methodology that esitimates at the early part of the time series may be biased high when it starts in the middle of an established epidemic outbreak and does not include the early history. It is simply avoided by projecting backwards an exponential growth rate based on the first few cases, essentially padding out the first lead in to the first few estimates.

## Prior selection

The default implementation uses the same fixed prior gamma distribution for $R_t$ for all points in the timeseries. This is configurable but recommended to be set to a value (e.g. 5). Reversion to the prior $R_t$ when case incidence gets very low, means R at very low values may become biased towards higher values. An alternative to this fixed prior, that assumes that estimates of $R_t$ are likely to be continuous in time is to use previous posterior values as priors for the next time point. This must be combined with a scale factor that increases the standard deviation of the prior distribution compared to the posterior of the previous time step, whilst keeping the mean constant, to prevent previous posterior estimates dominating the  subsequent estimates. By enforcing the continuity in time the aim is to stabilise noisy estimates of $R_t$ when incidence is low. On the down side this strategy may worsen the over-precise estimates seen when case numbers are high.

## Windowing strategy and posterior estimate selection

The selection of a windowing parameter may have, as we seen previously, a significant effect on the bias variance trade-off, and as observed before selecting a single window produces estimates that may either be too precise or too noisy. Picking the right value is also constrained by the fact that in the face of weekly periodicity of case incidence, $R_t$ estimates may overfit the data when windows are too short.It is not significantly more effort to calculate all the windows at the same time, and this opens up some options to select the window in a different way.

The first possibility is to adopt an adaptive strategy allows window selection to be determined by the case incidence within the window ($\sum I_t$). By selecting longe windows where case numbers are small we both improve the certainty of the estimate, and reduce its noise, and when case numbers are high we reduce the window size to allow more rapid adaption to changing $R_t$, with less risk of over-fitting. This stategy is summarised as follows where $R^{adaptive}$ is the set of estimates where the window size $\tau$ is the smallest possible value that encompasses enough data. 

$$
R^{adaptive}(t, \tau_{min}, \tau_{max}, I_{min}) = \{R^{profiles}(t, \tau) : \tau =min\Big(\tau_{max}\Big|\tau_{min} \leq \tau; I_{min} \leq \sum_{s=t-\tau+1}^t I_s\Big)\}
$$

In the validation study we observe the EpiEstim reference implementation given set number of days produces a lagged, over-precise estimate with a small bias. The degree of lag therefore determines the overall accuracy of the method when $R_t$ is rapidly changing. This happens because the assumption that $R_t$ is constant over a window period $\tau$ is violated. The degree of precision is therefore unwarranted in this situation. With the different time windows estimates there are a set of estimates looking backwards in time that are valid, and capture different assumptions about $R_t$. If the estimation is being done retrospectively there are also estimates from time points in the future ($s$) up to $t+\tau$ that are also relevant to time $t$ as the $R_s,\tau$ estimate assumes the reproduction number is constant over the time period $s-\tau-1 \dots s$. If we consider allowing $\tau$ to vary between two limits ($\tau_{min} \leq \tau \leq \tau_{max}$) then we can describe the set of all estimates of effective $R_t$ that are relevant to a single time point as $R_{t,all}$:

$$
R^{all}(t,\tau_{min}, \tau_{max}) = \{R^{profiles}(s,\tau) : \tau_{min} \leq \tau \leq \tau_{max} ; t \leq s \leq t+\tau\}
$$


```{r}
windows = tibble(t = 1:20+0.5) %>% tidyr::crossing(tibble(tau = 1:7)) %>% mutate(s = t - tau, delay=t-10, omega=s-10, relevant = s<10 & t>=10, label = paste0("\u03C4 = ",tau) %>% ordered(paste0("\u03C4 = ",1:7)) )

p = ggplot(windows%>% filter(relevant))+
  geom_rect(xmin = 10, xmax=11,ymin=0,ymax=Inf,fill="grey90",colour=NA)+
  geom_rect(aes(xmin=s,xmax=t,ymin=tau+delay/10+0.15,ymax=tau+delay/10+0.15),colour="red")+
  geom_rect(aes(xmin=s-5,xmax=s,ymin=tau+delay/10+0.15,ymax=tau+delay/10+0.15),colour="grey60")+
  geom_point(aes(x=t,y=tau+delay/10+0.15),colour="red")+
  #geom_point(aes(x=s,y=tau+delay/10+0.15),colour="red",shape="diamond")+
  scale_x_continuous(breaks=0:30+0.5,labels=0:30,minor_breaks = 0:31)+
  scale_y_continuous(breaks=1:7+0.5,labels=paste0("\u03C4 = ",1:7),minor_breaks = 0:8)+
  theme(panel.grid.major.y = element_blank(), panel.grid.minor.y = element_line(),panel.grid.minor.x = element_line(),panel.grid.major.x = element_blank())+
  coord_fixed(xlim=c(0.5,NA))+
  guides(colour=guide_none())+
  ylab(NULL)

p %>% saveThirdPageFigure(output("estimation-windows"))

```
*Figure 1: A graphical representation of the niforamtion involved in estimates of $R_t$ using the Cori method with different length windows (y-axis). The highlighted estimates (red dots) all use estimation windows that span the 10th day and during each of these windows there is an assumption of constant $R_t$. In situations where the true $R_t$ is dynamic, combining these estimates may reflect the overall uncertainty.*

All possible combinations of window and future time point $R_t$ estimates that are relevant to a specific point in time is show in figure 1. Each red point represents an $R_t$ estimate that is based on some assumption about the reproduction number on day 10 on this plot. All of these estimates may be combined to produce a final $R_t$ estimate for day 10.This set of estimates provides a broader set of assumptions than a single window can provide and therefore may reduce the unwanted over-precision of estimates when $R_t$ is changing rapidly.

## Combining posterior estimates

In all the estimates thus far ($R^{profiles}$,$R^{adaptive}$, and $R^{all}$) there are a set of posterior gamma distributions for each time point. This is either because there are multiple infection profiles, expressing uncertainty, or there are multiple windows over which the estimate is calculated, or there are multiple days over which the estimates are collected. These estimates must be combined, and there are different possible strategies for doing this. 

In the default implementation the multiple estimates are combined by constructing an empirical distribution using Monte-Carlo random sampling from the posterior gamma distributions of all estimates. Quantiles are estimated from this empirical distribution. This is not deterministic and for a reasonable degree of accuracy is computationally expensive.

When we consider that the only information we need to get from the mixture of posterior distributions is a set of quantiles, an alternative strategy therefore is to construct this mixture distribution from the set of posteriors and solve it numerically for the quantiles. Given random sampling does the same process in an un-targeted way this is actually less overall effort and provides a deterministic result.

The posterior estimates should be similar to one another. A reasonable approximation therefore is to consider the mixture distribution as another gamma distribution with first and second moments matching those of the mixture distribution. This is quick to calculate and allows us to rapidly combine the large number of estimates that arise from the multiplicative combinations of infection profiles, variable window length and variable day of estimate. The quality of this estimate will depend on how different the distributions are from each other, but this again produces a deterministic result. The parameterisation of the estimated gamma distribution is expressed below in terms of shape ($\alpha$) and rate ($\beta$) parameters, composed of a mixture of gamma distributions ($\sim Gamma(\alpha_i,\beta_i$) from the posterior estimates.

$$ 
\begin{aligned}
E[X] = \mu = \frac{\alpha}{\beta} &= \frac{1}{n} \sum_1^n  \mu_i = \frac{1}{n} \sum_1^n  \frac{\alpha_i}{\beta_i} \\
E[(X-\mu)^2] = \sigma^2 = \frac{\alpha}{\beta^2} &= E[X^2]-\mu^2 \\
&= \frac{1}{n} \Big(\sum_1^n E[X_i^2]\Big) - \mu^2 \\
&= \frac{1}{n} \Big(\sum_1^n \sigma_i^2+\mu_i^2\Big) - \mu^2 \\
&= \frac{1}{n} \Big(\sum_1^n \frac{\alpha_i}{\beta_i^2}+\big(\frac{\alpha_i}{\beta_i}\big)^2 \Big) - \big(\frac{1}{n} \sum_1^n\frac{\alpha_i}{\beta_i}\Big)^2 \\
&= \frac{1}{n} \Big(\sum_1^n \frac{\alpha_i}{\beta_i^2}+\frac{\alpha_i^2}{\beta_i^2} - \frac{1}{n} \frac{\alpha_i^2}{\beta_i^2}\Big) \\
&= \frac{1}{n} \Big(\sum_1^n \frac{\alpha_i+\frac{n-1}{n}\alpha_i^2}{\beta_i^2}\Big) \\

\alpha = \frac{\mu^2}{\sigma^2} &= \frac{1}{n} \frac{\Big(\sum_1^n\frac{\alpha_i}{\beta_i}\Big)^2}{\Big(\sum_1^n \frac{\alpha_i+\frac{n-1}{n}\alpha_i^2}{\beta_i^2}\Big)} \\
\beta = \frac{\mu}{\sigma^2} &= \frac{\Big(\sum_1^n\frac{\alpha_i}{\beta_i}\Big)}{\Big(\sum_1^n \frac{\alpha_i+\frac{n-1}{n}\alpha_i^2}{\beta_i^2}\Big)}
\end{aligned}
$$

In all the strategies described above there is the potential to weight specific estimates more than others. As each infectivity profile is taken to be equally likely this only make sense when combining estimates made over many time windows, based on a function of the size of the window, or potentially a function of the number of cases observed within the window.

# Validation comparison

In this section we compare the performance of different estimation strategies on the task of estimating $R_t$ using the methodology described before, against the same synthetic time series. Each comparison involves understanding the lag, accuracy and precision, of the estimates.

## Fixed versus adaptive priors.

In this comparison we are looking at the performance allowing for change only in the prior selection, and in the configuration

```{r}

# reference implementation
reference = function(ts, infectivityProfile)  {
  estim1 = J$CoriEstimator$new(r0Mean = 1.2,r0SD = 4,maxWindow = 14)
  estim1$withInfectivityProfile(infectivityProfile, replace = TRUE)
  estim1$withDefaultPrior()
  estim1$atStartOfTimeseries()
  estim1$selectSpecificWindow(7)
  estim1$estimateRt(ts %>% group_by(subgroup),dateColName = "date",incidenceColName = "value")
}

middleTs = function(ts, infectivityProfile)  {
  estim1 = J$CoriEstimator$new(r0Mean = 1.2,r0SD = 4,maxWindow = 14)
  estim1$withInfectivityProfile(infectivityProfile, replace = TRUE)
  estim1$withDefaultPrior()
  estim1$inMiddleOfTimeseries()
  estim1$selectSpecificWindow(7)
  estim1$estimateRt(ts %>% group_by(subgroup),dateColName = "date",incidenceColName = "value")
}

adaptive = function(ts, infectivityProfile) {
  estim3 = J$CoriEstimator$new(r0Mean = 1.2,r0SD = 4,maxWindow = 14)
  estim3$withInfectivityProfile(infectivityProfile, replace = TRUE)
  estim3$withDefaultPrior()
  estim3$inMiddleOfTimeseries()
  estim3$selectSpecificWindow(7)
  estim3$withAdaptivePrior(factor = 1.25)
  estim3$estimateRt(ts %>% group_by(subgroup),dateColName = "date",incidenceColName = "value")
}

estimators = tibble(
  model = forcats::as_factor(c(
    "EpiEstim: 7 day",
    "Start correction",
    "Adaptive prior"
  )), 
  estimFn = c(
    reference,
    middleTs,
    adaptive
  )
)

lagAnalysisResult = lagAnalysis(estimators)
qualityAnalysisResult = qualityAnalysis(estimators, lagAnalysisResult$modelLag)

p3 = qualityAnalysisResult %>% estimationExamplePlot(subgroups = 2)
p3 %>% saveHalfPageFigure(output("qualitative-prior-selection"))

```


```{r}
lagAnalysisResult %>% lagPlot() %>% saveThirdPageFigure(output("lag-prior-selection"))
```

```{r}

p = estimateSummaryPlot(qualityAnalysisResult)
p %>% saveHalfPageFigure(output("error-summary-prior-selection"))

```

## Combining 

In this comparison we are looking at the performance allowing for change only in the combining methods
Uncertain serial interval assumptions

```{r}

si = SerialIntervalProvider$uncertainGamma()

# reference implementation
reference = function(ts, infectivityProfile)  {
  estim1 = J$CoriEstimator$new(r0Mean = 1.2,r0SD = 4,maxWindow = 14)
  estim1$withInfectivityProfile(infectivityProfile, replace = TRUE)
  estim1$withDefaultPrior()
  estim1$inMiddleOfTimeseries()
  estim1$selectSpecificWindow(7)
  estim1$collectResampledQuantiles()
  estim1$estimateRt(ts %>% group_by(subgroup),dateColName = "date",incidenceColName = "value")
}

adaptiveWindow = function(ts, infectivityProfile)  {
  estim1 = J$CoriEstimator$new(r0Mean = 1.2,r0SD = 4,maxWindow = 14)
  estim1$withInfectivityProfile(infectivityProfile, replace = TRUE)
  estim1$withDefaultPrior()
  estim1$inMiddleOfTimeseries()
  estim1$collectMixtureQuantiles()
  estim1$estimateRt(ts %>% group_by(subgroup),dateColName = "date",incidenceColName = "value")
}

allWindows = function(ts, infectivityProfile) {
  estim1 = J$CoriEstimator$new(r0Mean = 1.2,r0SD = 4,maxWindow = 14)
  estim1$withInfectivityProfile(infectivityProfile, replace = TRUE)
  estim1$withDefaultPrior()
  estim1$inMiddleOfTimeseries()
  estim1$collectMixtureApproximation()
  estim1$estimateRt(ts %>% group_by(subgroup),dateColName = "date",incidenceColName = "value")
}

estimators = tibble(
  model = forcats::as_factor(c(
    "Random resampling",
    "Adaptive window",
    "All windows"
  )), 
  estimFn = c(
    reference,
    adaptiveWindow,
    allWindows
  )
)

lagAnalysisResult = lagAnalysis(estimators)
qualityAnalysisResult = qualityAnalysis(estimators, lagAnalysisResult$modelLag)

p3 = qualityAnalysisResult %>% estimationExamplePlot(subgroups = 2)
p3 %>% saveHalfPageFigure(output("qualitative-posterior-selection"))

```


```{r}
lagAnalysisResult %>% lagPlot() %>% saveThirdPageFigure(output("lag-prior-selection"))
```

```{r}

p = estimateSummaryPlot(qualityAnalysisResult)
p %>% saveHalfPageFigure(output("error-summary-prior-selection"))

```

## Posterior selection.

In this comparison we are looking at the performance allowing for change only in the prior selection, and in the configuration

```{r}

# reference implementation
reference = function(ts, infectivityProfile)  {
  estim1 = J$CoriEstimator$new(r0Mean = 1.2,r0SD = 4,maxWindow = 14)
  estim1$withInfectivityProfile(infectivityProfile, replace = TRUE)
  estim1$withDefaultPrior()
  estim1$atStartOfTimeseries()
  estim1$selectSpecificWindow(7)
  estim1$estimateRt(ts %>% group_by(subgroup),dateColName = "date",incidenceColName = "value")
}

adaptiveWindow = function(ts, infectivityProfile)  {
  estim1 = J$CoriEstimator$new(r0Mean = 1.2,r0SD = 4,maxWindow = 14)
  estim1$withInfectivityProfile(infectivityProfile, replace = TRUE)
  estim1$withDefaultPrior()
  estim1$inMiddleOfTimeseries()
  estim1$selectAdaptiveWindow(incidenceSum = 100)
  estim1$estimateRt(ts %>% group_by(subgroup),dateColName = "date",incidenceColName = "value")
}

allWindows = function(ts, infectivityProfile) {
  estim1 = J$CoriEstimator$new(r0Mean = 1.2,r0SD = 4,maxWindow = 14)
  estim1$withInfectivityProfile(infectivityProfile, replace = TRUE)
  estim1$withDefaultPrior()
  estim1$inMiddleOfTimeseries()
  estim1$selectMixtureCombination()
  estim1$estimateRt(ts %>% group_by(subgroup),dateColName = "date",incidenceColName = "value")
}

estimators = tibble(
  model = forcats::as_factor(c(
    "EpiEstim: 7 day",
    "Adaptive window",
    "All windows"
  )), 
  estimFn = c(
    reference,
    adaptiveWindow,
    allWindows
  )
)

lagAnalysisResult = lagAnalysis(estimators)
qualityAnalysisResult = qualityAnalysis(estimators, lagAnalysisResult$modelLag)

p3 = qualityAnalysisResult %>% estimationExamplePlot(subgroups = 2)
p3 %>% saveHalfPageFigure(output("qualitative-posterior-selection"))

```


```{r}
lagAnalysisResult %>% lagPlot() %>% saveThirdPageFigure(output("lag-posterior-selection"))
```

```{r}

p = estimateSummaryPlot(qualityAnalysisResult)
p %>% saveHalfPageFigure(output("error-summary-posterior-selection"))

```