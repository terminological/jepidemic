---
title: "Appendix D - Bayesian growth rate and reproduction number estimation"
author: "Rob Challen"
date: '`r format(Sys.Date(), "%d-%m-%Y")`'
output: 
  pdf_document :
    fig_caption: yes
    keep_tex: TRUE
header-includes:
 \usepackage{float}
 \usepackage{mathtools}
 \usepackage{amsmath}
 \DeclareRobustCommand{\[}{\begin{equation*}}
 \DeclareRobustCommand{\]}{\end{equation*}}
 \newcounter{tagno}
 \setcounter{tagno}{0}
 \let\amsmathtag\tag
 \renewcommand{\tag}[1]{\amsmathtag{\thetagno} \label{#1} \stepcounter{tagno}}
 \floatplacement{figure}{H}    
knit: (function(inputFile, encoding,...) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "~/Dropbox/sarscov2/r-estimation-methodology", output_file=paste0('appendix-D-bayesian-growth-rate-',Sys.Date(),'.pdf')) })
fig_width: 7
fig_height: 5
out.width: "100%"
bibliography: jepidemic.bib
csl: jepidemic.csl
vignette: >
  %\VignetteIndexEntry{Cori method}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)


here::i_am("vignettes/bayesian-growth-rate.Rmd")
source(here::here("vignettes/common-setup.R"))

```

# Introduction

In previous appendices we demonstrated approaches to estimating the growth rate using a maximum likelihood estimator, and the effective reproduction number ($R_t$) using a Bayesian framework with specific assumptions about the exponential growth resulting from the reproduction number. In this section we derive another simpler method for deriving both quantities within a single Bayesian framework, using minimal assumptions about the underlying processes as a counterpoint for comparison. This method is implemented in a Java library with bindings to the R language called "jepidemic", which is open source and available on GitHub [CITE]. 

# Estimation of the incidence of infection

As in previous appendices we assume $I_0, I_1, \dots, I_t$ is a time series of infection counts, assumed to be drawn from some discrete probability distribution with expected value $\overline{I_t}$. We assume $I_t$ is a Poisson distributed quantity, with a rate parameter which is a function of time:


$$
\begin{aligned}
E[I_t] &= \lambda_t \\
\end{aligned}
$$

If we assuming $\lambda_t$ is constant over a short time period $[t-\tau;t+\tau]$ then by the definition of the Poisson distribution:


$$
\begin{aligned}
P(I_{t-\tau},\dots,I_{t+\tau}|\lambda_t) &= \prod_{s=t-\tau}^{t+\tau}\frac{e^{-\lambda_t}\lambda_t^{I_s}}{I_s!} \\
\end{aligned}
$$

Using our knowledge of the conjugate prior of the Poisson distribution we assume the rate parameter, $\lambda_t$, to be gamma distributed with shape parameter $\alpha$ and rate parameter $\beta$, and if $n = 2\tau+1$ then we can use a Bayesian framework to derive posterior estimates of the distribution of the Poisson rate, labelled $\alpha'$ and $\beta'$ conditioned on the data we observe over $[t-\tau;t+\tau]$:

$$
\begin{aligned}
P(I_{t-\tau},\dots,I_{t+\tau}|\lambda_t) &= \frac{e^{-n\lambda_t}\lambda_t^{\sum{I_s}}}{\prod_{s=t-\tau}^{t+\tau}I_s!} \\
P(\lambda_{t}) &= \frac{\beta^\alpha}{\Gamma(\alpha)} \lambda_{t}^{\alpha-1}e^{-\beta\lambda_{t}} \\
P(\lambda_t|I_{t-\tau},\dots,I_{t+\tau}) &= \frac{P(I_{t-\tau},\dots,I_{t+\tau}|\lambda_t)P(\lambda_{t})}{P(I_{t-\tau},\dots,I_{t+\tau})}\\
P(\lambda_t|I_{t-\tau},\dots,I_{t+\tau}) &= \frac{e^{-n\lambda_t}\lambda_t^{\sum{I_s}}}{\prod_{s=t-\tau}^{t+\tau}I_s!}\frac{\beta^\alpha}{\Gamma(\alpha)} \lambda_{t}^{\alpha-1}e^{-\beta\lambda_{t}}\\
P(\lambda_t|I_{t-\tau},\dots,I_{t+\tau}) &\propto \lambda_t^{\sum{I_s+\alpha-1}}e^{-(2\tau+1+\beta)\lambda_t} \\
P(\lambda_t|I_{t-\tau},\dots,I_{t+\tau}) &\sim \Gamma\big(\sum_{t-\tau}^{t+\tau}{I_s}+\alpha, 2\tau+1+\beta\big)\\
\alpha' &= \alpha+\sum_{t-\tau}^{t+\tau}{I_s}\\
\beta' &= 2\tau+1+\beta
\end{aligned}
\tag{eq:bayesPois}
$$

The posterior estimate of the Poisson rate $\lambda$ is gamma distributed by definition. An estimate of the likely value of $I_t$ ($\overline{I_t}$) given the observed data is given by the posterior predictive distribution:

$$
\begin{aligned}
\overline{I_t} &\sim NegBin\Big(\alpha',\frac{1}{\beta'+1}\Big)\\
E(\overline{I_t}|I_{t-\tau},\dots,I_{t+\tau}) &= \frac{\alpha'}{\beta'} \\
V(\overline{I_t}|I_{t-\tau},\dots,I_{t+\tau}) &= \alpha'\Big(\frac{\beta'+1}{\beta'^2}\Big)
\end{aligned}
$$

<!-- There is probably something interesting we can do with the $P(\overline{I_t}|I_{t-\tau} \dots I_{t+\tau})$ to detect importation or anomaly events -->
<!-- N.B. need to talk about prior selection. -->

# Estimation of the growth rate

The exponential growth rate $r_t$ is the gradient of the logarithm of $I$ ($\frac{d}{dt}log(\overline{I_t})$) with respect to time. We approximate this as the difference between two estimates of the true value of $I$ separated by a small time period $2m$:

$$
\begin{aligned}
r_t &\approx \frac{1}{2m}(log(E(I_{t+m}))-log(E(I_{t-m}))) \\
r_t &= \frac{1}{2m}log\frac{\lambda_{t+m}}{\lambda_{t-m}}
\end{aligned}
$$
Given that $I$ is assumed to be Poisson distributed the expected value is $\lambda_t$. If we further define $y = g(r)$ such that:

$$
\begin{aligned}
y = g(r_t) &= e^{2\tau r_t}\\
r_t = g^{-1}(y) &= \frac{1}{2\tau}log(y)\\
\end{aligned}
$$

Then we can express the distribution of $g(r)$ in terms of a ratio of Gamma distributed quantities. For simplification we have also assumed that $m=\tau$. This means that is estimating the growth rate we use two posterior estimates of the Poisson rate based on $\tau+1$ data points. The growth rate estimate is therefore based on $2\tau+1$ data points, as the central point overlaps. This is a choice made to simplify the mathematics but we could have used any 2 estimates which are close together. This approach also has the benefit of not re-using information. 

$$
\begin{aligned}
r_t &= \frac{1}{2\tau}log\frac{\lambda_{t+\tau}}{\lambda_{t-\tau}} \\
g(r_t) &\sim \Bigg(\frac{Gamma(\alpha+\sum_{s=t}^{t+2\tau}{I_s}, \beta')}{Gamma(\alpha+\sum_{r=t-2\tau}^{t}{I_r}, \beta')}\Bigg) \\
\alpha'_{\tau+} &= \alpha+\sum_{t}^{t+2\tau}{I_s}\\
\alpha'_{\tau-} &= \alpha+\sum_{t-2\tau}^{t}{I_s}\\
g(r_t) &\sim \Bigg(\frac{
Gamma(\alpha'_{\tau+}, \beta')
}{
Gamma(\alpha'_{\tau-}, \beta')
}
\Bigg)\\
\end{aligned}
$$

The ratio of 2 gammas with same rate parameter is a Beta Prime distributed quantity [CITE], which describes $g(r)$: 

$$
\begin{aligned}
r_t \sim Y &= \frac{1}{2\tau}log\Big(BetaPrime\big(\alpha'_{\tau+}, \alpha'_{\tau-})\Big) \\
g(r_t) \sim X &= BetaPrime\big(\alpha+\sum_{t}^{t+2\tau}{I}, \alpha+\sum_{t-2\tau}^{t}{I}\big) \\
BetaPrime(\alpha_1, \alpha_2) &: \\
f(x) &= \frac{1}{B(\alpha_1,\alpha_2)}x^{\alpha_1-1}(1+x)^{-\alpha_1-\alpha_2} \\
F(x) &= I_{
\frac{x}{1+x}}(\alpha_1,\alpha_2)
\end{aligned}
\tag{eq:rtBetaP}
$$
Where $I$ is the regularised beta function and $B$ is the complete beta function. The support for $g(r_t)$ is $[0 \dots \infty]$ and hence the support for $r_t$ is $[-\infty \dots \infty]$. Given that $g(r_t)$ can be differentiated and is a strictly increasing function we can apply the following transformation:

https://www.statlect.com/fundamentals-of-probability/functions-of-random-variables-and-their-distribution
https://www.probabilitycourse.com/chapter4/4_1_3_functions_continuous_var.php

$$
\begin{aligned}
Y &= \frac{1}{2\tau}log(X) \\
g(x) &= \frac{1}{2\tau}log(x) \\
g^{-1}(y) &= e^{2\tau y} \\
\frac{dg^{-1}}{dy} &= 2\tau e^{2\tau y}\\
F_Y(y) &= F_X(g^{-1}(y)) \\
f_Y(y) &= f_X(g^{-1}(y)) \frac{dg^{-1}(y)}{dy}
\end{aligned}
$$

Which gives us a probability density function for an estimate of $r_t$ based on the Bayesian posterior of $\lambda_t$:
$$
\begin{aligned}
f_Y(r_t) &= f_X(g^{-1}(r_t))\frac{dg^{-1}(r_t)}{dr_t}\\
f_Y(r_t) &= 2\tau e^{2\tau r_t}f_X(e^{2\tau r_t})\\
f_Y(r_t) &=  2\tau e^{2\tau r_t}\frac{
\Big(
  e^{r_t(\alpha'_{\tau+}-1)}
  (1+e^{r_t})^{(-\alpha'_{\tau+}-\alpha'_{\tau-})}
\Big)}{B(\alpha'_{\tau+}, \alpha'_{\tau-})}\\
f_Y(r_t) &=  \frac{2\tau}{B(\alpha'_{\tau+}, \alpha'_{\tau-})}
\Big(
  e^{r_t(\alpha'_{\tau+}+2\tau-1)}
  (1+e^{r_t})^{(-\alpha'_{\tau+}-\alpha'_{\tau-})}
\Big)\\
\end{aligned}
$$

and which has the following cumulative probability function:

$$
\begin{aligned}
F_Y(r_t) &= F_Y(g^{-1}(r_t))\\
F_X(r_t) &= F_Y(e^{2\tau r_t})\\
F_X(r_t) &= I_{
\frac{e^{2\tau r_t}}{1+e^{2\tau r_t}}}(\alpha_{\tau+},\alpha_{\tau-})
\end{aligned}
$$

where $I_x(a,b)$ is the regularised Beta function.

https://mathworld.wolfram.com/RegularizedBetaFunction.html
https://commons.apache.org/proper/commons-math/javadocs/api-3.3/org/apache/commons/math3/special/Beta.html
https://en.wikipedia.org/wiki/Beta_prime_distribution#Properties

The quantile function for $g(r_t)$ is similarly transformed backwards to give a quantile estimate for $r_t$, and we can sample from $Y$ and transform using $g^{-1}(y)$ to get unbiased samples of $r_t$.

# Reproduction number estimates from Poisson rate

If we continue to assume $I_t \sim Poisson(\lambda_t)$ and an estimate of $\lambda_t$ is available. As before $\omega_1, \omega_2, \dots, \omega_s$ is another probability distribution, the infectivity profile, that defines the likelihood that a case infected at time $t$ resulted from a case infected between the times $t-s$ and $t-s+1$. This definition implies that $\omega_{s \leq 0} = 0$ as that applies to infections in the future, and that the discrete time measure $s$ here represents the upper bound of the equivalent continuous unit time interval, rather than, for example, the middle of the interval. 

As before we define the backward-looking effective reproduction number $R_t$ as the inverse ratio of the number of primary infections associated with secondary infections observed at time $t$, this is known as the instantaneous reproduction number. 

$$
R_t = \frac{\overline{I_t}}{\sum_{s=1}^t \overline{I_{t-s}}\omega_s}
$$
The posterior distribution of $\lambda_t$ is an estimate of the $\overline{I_t}$ distribution and therefore . 

$$
R_t = \frac{\lambda_t}{\sum_{s=1}^t \lambda_{t-s}\omega_s}
$$

assuming the posterior distribution of $\lambda_t \sim Gamma(\alpha',\beta')$ as described above., we consider the denominator as the sum of scaled gamma distributions, and we can say the distribution of the denominator is of the form:

$$
\lambda_{t-s}\omega_s \sim Gamma\big(\alpha'_{t-s}, \frac{\beta'_{t-s}}{\omega_s}\big)\\ 
$$

A commonly used approximation for a sum of gamma distributed variables is as another gamma distribution with the same first and second moments as described by in Cove et al [CITE]. In the case of a set of gamma distributions, with parameters $\alpha_i$ and $\beta_i$, an approximation of the sum is another gamma distribution with parameters $\alpha_{sum}$ and $\beta_{sum}$:

$$
\begin{aligned}
E(X_i) &= \frac{\alpha_i}{\beta_i}\\
V(X_i) &= \frac{\alpha_i}{\beta_i^2}\\
E(X_{sum}) &= \sum_iE(X_i) =  \sum_i\frac{\alpha_i}{\beta_i}\\
V(X_{sum}) &= \sum_iV(X_i)= \sum_i\frac{\alpha_i}{\beta_i^2}\\
\alpha_{sum} &= \frac{E(X_{sum})^2}{V(X_{sum})} = \frac{\Big(\sum_i\frac{\alpha_i}{\beta_i}\Big)^2}{\sum_i\frac{\alpha_i}{\beta_i^2}}\\
\beta_{sum} &= \frac{E(X_{sum})}{V(X_{sum})} = \frac{\sum_i\frac{\alpha_i}{\beta_i}}{\sum_i\frac{\alpha_i}{\beta_i^2}}\\
\end{aligned}
$$

1. Covo S, Elalouf A. A novel single-gamma approximation to the sum of independent gamma variables, and a generalization to infinitely divisible distributions. Electronic Journal of Statistics [Internet]. 2014 Jan [cited 2021 Nov 25];8(1):894–926. Available from: https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-8/issue-1/A-novel-single-gamma-approximation-to-the-sum-of-independent/10.1214/14-EJS914.full

The moment matching approximation for the sum of gamma distributions can be empirically tested. Here we demonstrate its use on a random set of five gamma distributions show in panel A and the sum of a million random draws from each of these probability distributions in panel B. In panel B the red line is the predicted Gamma distribution based on the estimator. Further validation of the estimator is warranted but in simple cases the estimator is observed to perform well.

```{r}
seed = 101
means = runif(5,min = 1,max=2)
sds = runif(5,min=0.1,max=0.5)

alphas = (means/sds)^2
betas = means/sds^2

alphaSum = sum(alphas/betas)^2/(sum(alphas/betas^2))
betaSum = alphaSum / sum(alphas/betas)

meanSum = alphaSum/betaSum
sdSum = sqrt(alphaSum/betaSum^2)

data = tibble(alpha = alphas, beta = betas, type = rep("component",5), distribution=1:5)
pdfs = data %>% group_by_all() %>% summarise(
  x=seq(0,3,length.out = 1001), 
  p=dgamma(x,alpha,beta))

p1 = ggplot(pdfs %>% ungroup(), aes(x=x,y=p,colour=as.factor(distribution)))+geom_line()+guides(colour=guide_none())+ylab("P(x)")

hist = data %>% group_by(distribution) %>% 
  summarise(
    y = rgamma(1000000,alpha,beta),
    sample = 1:1000000
  ) %>%
  group_by(sample) %>% 
  summarise(sum_y = sum(y))


              
estim = tibble(alpha =alphaSum, beta = betaSum) %>% group_by_all() %>% summarise(
  x=seq(min(hist$sum_y),max(hist$sum_y),length.out = 2001), 
  p=dgamma(x,alpha,beta)
)

p2 = ggplot(hist,aes(x=sum_y))+geom_histogram(aes(y = 10*stat(count / sum(count))),binwidth = 0.1,fill=NA,colour="grey50")+
  geom_line(data=estim, mapping = aes(x=x,y=p),colour="red")+xlab(latex2exp::TeX("$\\sum x$"))+ylab(latex2exp::TeX("$P(\\sum x)$"))

p1+p2+patchwork::plot_annotation(tag_levels = "A")
```

Using this approximation we estimate $R_t$ to be distributed as the ratio of 2 Gamma distributions: the numerator with shape and rate parameters $\alpha'$ and $\beta'$, and the denominator with shape and rate parameters $\alpha''$ and $\beta''$ as described:

$$
\begin{aligned}
R_t &\sim \frac{
  \beta_t'Gamma(\alpha_t',1)
}{
  \beta_t''Gamma(\alpha_t'',1)
}\\
R_t &\sim BetaPrime(\alpha_t',\alpha_t'',1,\frac{\beta_t''}{\beta_t'})\\
\text{Where given: } s \in (1 .. t) &\\
\alpha''_t &= 
\frac{
  \Big(\sum_s \frac{\alpha'_{t-s}\omega_s}{\beta'_{t-s}}\Big)^2
}{
  \sum_s \frac{\alpha'_{t-s}\omega_s^2}{(\beta'_{t-s})^2}
}\\
\beta''_t &= 
\frac{
  \sum_s \frac{\alpha'_{t-s}\omega_s}{\beta'_{t-s}}
}{
  \sum_s \frac{\alpha'_{t-s}\omega_s^2}{(\beta'_{t-s})^2}
}\\
\end{aligned}
\tag{eq:RtGenBetaP}
$$
This distributional form of $R_t$ as a generalised Beta Prime distribution with three shape parameters ($\alpha_1,\alpha_2,\alpha_3$) and one scale parameter ($\beta$) and with the probability density and cumulative probability functions as given below:

$$
\begin{aligned}
\text{Where } BetaPrime(\alpha_1,\alpha_2,\alpha_3,\beta)&: \\
f(x) &= \frac{
\alpha_3\Big(
  1+\big(
    \frac{x}{\beta}
  \big)^{\alpha_3}
\Big)^{-\alpha_1-\alpha_2}
\Big(
  \frac{x}{\beta}
\Big)^{\alpha_1\alpha_3-1}
}
{
\beta Beta(\alpha_1,\alpha_2)
}\\
F(x) &= I_{
  \frac{x^{\alpha_3}}{x^{\alpha_3}+\beta^{\alpha_3}}
}\big(\alpha_1,\alpha_2\big)
\end{aligned}
$$
and where $I_x$ is the regularised Beta function. This form for the $R_t$ estimate assumes only the Gamma posterior estimate for the Poisson rate, and so can be readily calculated directly from the analytic form of the posteriors identified in the first part of this method. This could be a biased if the denominator of the ratio is not a good estimate for the weighted sum in reality, however the moment matching estimate works well when the distributions are not completely different. In our case the fact that the $\lambda_t$ estimates are part of the same time series and scaled by the infectivity profile, does make it quite likely the distributions will have similar characteristics. 

This constitutes a method for estimating the expected incidence, the growth rate, and the instantaneous reproduction number from a time series of observed case incidence making only a minimal set of assumptions.

# Implementation considerations

In $\eqref{eq:bayesPois}$ we derived the standard posterior Gamma distribution of a Poisson rate parameter based on observed cases and a prior belief about that rate ($\lambda_t$). The prior belief about the rate at time $t$ can be informed by the value of the rate at earlier times, and optionally by the growth rate such that $I_{t+1} = I_te^{r_t}$. The full distributional forms of the posteriors at previous time steps could be used to generate a prior, but this was found to result in a prior that is far too strong and reflects the the assumption that the Poisson rate is constant over a small time period. Instead of this a better option is a prior that has a very low coefficient of variation, and we found a value of 1 to be appropriate, resulting in the distributional form for the prior, $\lambda_{t+1}$ in terms of the posterior of incidence ($\lambda'_t$) and growth rate ($r'_t$). 

$$
\lambda_{t+1} \sim Gamma(1,\frac{1}{\overline{\lambda'_{t}} e^\overline{r'_t}}})
$$

This prior will influence the posterior estimates of incidence most strongly when incidence is low, and this may indeed have a desirable stabilising effect on the estimates in this situation. Increasing the coefficient of variation from 1 to a higher number may provide additional stability and is a topic for future exploration.

As stated the method does not account for uncertainty in the infectivity profile $\omega_s$. This can be included by sampling the infectivity profile, and estimating an $R_t$ distribution for each infectivity profile. The estimator for $R_t$ can be made using any posterior estimate of $\lambda_t$, for which we have a range of possibilities based on the desired data window ($\tau$) we wish to use. Much as in Appendix B there are potentially $R_t$ estimates for each of the data window sizes selected for $\lambda_{t,\tau}$ and each of the infectivity profiles. These multiple estimates are combined as a weighted mixture distribution of the multiple $R_t$ estimates, to generate an overall summary estimate while retaining uncertainty By default a uniform weighting is applied but non uniform weighting based on the window size is also a topic for future exploration.

As described in appendix A the case counts may have weekly periodicity, or have anomalous values for other reasons. Within this framework it is possible to adjust the weighting of each data point on a case by case basis, by appropriately adjusting the posteriors in $\eqref{eq:bayesPois}$. This opens the door for increasing the uncertainty when estimates span weekends, for example, and warrants more investigation.   

# Growth rate validation

The growth rate estimates using this method can be compared to those from the maximum likelihood local polynomial approach described in Appendix C, with a polynomial degree of 2 and window of 14 days. This uses the same synthetic data and methodology as described in Appendix A. .

```{r}

locfitEstimator = function(deg,win) {
  return(function(ts, infectivityProfile) {
    locfitGrowthEstimate(ts, degree = deg, window = win)
  })
}

bayesian = function(ts, infectivityProfile) {
  grEstim = J$GrowthRateEstimator$new(minWindow = 4,maxWindow = 14)
  grEstim$withSaneDefaults()
  grEstim$withInfectivityProfileMatrix(infProf$yMatrix)
  out = grEstim$estimateGrowthRateSingle(ts, dateColName = "date",incidenceColName = "value")
}

# each estimator function must take a single time series and a single infectivity_profile object and produce a single 
# time series of the estimates. The input time-series will have a "date" and a "value" column.

estimators = tibble(
  model = forcats::as_factor(c(
    "Locfit",
    "Bayesian"
  )), 
  estimFn = c(
    locfitEstimator(2,14),
    bayesian
  )
)
```

```{r}
lagAnalysisResult = lagAnalysis(estimators, estimation="Growth")

qualityEstimates = syntheticEstimates(estimators)
qualityAnalysisResult = validationMetrics(qualityEstimates, modelLag=lagAnalysisResult$modelLag, estimation="Growth",criticalValue = 0)
 

```

The result of the comparison is shown qualitatively in figure D1, and shows the Bayesian estimator seems to perform well with comparable levels of uncertainty and close matching to the true value

```{r}

 
p3 = qualityAnalysisResult %>% estimationExamplePlot(estimation="Growth",ylim = c(-0.1,0.1))
p3 %>% saveHalfPageFigure(output("qualitative-bayesian-growth"))

```

*Figure D1: qualitative estimates of growth rate (black) against simulated (red) comparing the Bayesian estimator described here with the maximum likelihood Poisson model implementation from Appendix C*

As the growth rate estimates use two estimated of the Poisson rate centered around the time point in question we expect there to be no delay, similar to the locfit method. This is confirmed in figure D2.

```{r}
lagAnalysisResult %>% lagPlot(estimation="Growth",ylim=c(-0.2,0.2)) %>% saveThirdPageFigure(output("lag-bayesian-growth"))
```

*Figure D2: time delay analysis of growth rate (black) against simulated (red) comparing the Bayesian estimator described here with the maximum likelihood Poisson model implementation from Appendix C*

Quantitative comparison of the methods shown in Figure D3 and table D1 show the Bayesian method performs slightly better overall than the locfit method as judged by the continuous rank probability score, but with reassuringly little difference between the 2 methods.

```{r}

p = estimateSummaryPlot(qualityAnalysisResult)
p %>% saveHalfPageFigure(output("error-summary-bayesian-growth"))

```

*Figure C3: Estimate quality metric summaries for multiple estimation methods. In this instance we compare the Bayesian estimator described here with the maximum likelihood Poisson model implementation from Appendix C. Panel A show summary statistics for the bias of $R_t$ estimates, panel B shows the calibration. Panel C shows the quantile density, panel D the CRPS and panel E the critical threshold calibration.*

*Table C1: summary of quantitative analysis of $R_t$ (black) against simulated (red) comparing the Bayesian estimator described here with the maximum likelihood Poisson model implementation from Appendix C*

```{r}
summaryAnalysis(qualityAnalysisResult,lagAnalysisResult) %>% standardPrintOutput::saveTable(output("error-summary-bayesian-growth-table"),defaultFontSize = 7)
```

More detailed analysis did not demonstrate any obvious difference between the 2 methods although the Bayesian estimator is unable to produce a growth rate estimate right up to the end of the input time series. This is due to the symmetric nature of the estimation window, which is not a requirement for the locfit estimator.

# $R_t$ validation 

The derivation of the reproduction number within the Bayesian estimation framework can be compared to estimates from both the locally fitted polynomical locfit approach from Appendix C and the renewal equation approach from Appendix B. 

```{r}

locfitRtEstimator = function(deg,win) {
  return(function(ts, infectivityProfile) {
    locfitGrowthEstimate(ts, degree = deg, window = win) %>% rtFromGrowthRate(infectivityProfile)
  })
}

improved = function(ts, infectivityProfile) {
  estim1 = J$CoriEstimator$new(r0Mean = 1.2,r0SD = 4,maxWindow = 14)
  estim1$withInfectivityProfileMatrix(infectivityProfile$yMatrix)
  estim1$inMiddleOfTimeseries()
  estim1$withAdaptivePrior(factor = 1.25)
  estim1$selectMixtureCombination()
  estim1$collectMixtureApproximation()
  estim1$estimateRt(ts, dateColName = "date",incidenceColName = "value") %>% mutate(date = Rt.EndDate)
}

bayesian = function(ts, infectivityProfile) {
  grEstim = J$GrowthRateEstimator$new(minWindow = 4,maxWindow = 14)
  grEstim$withSaneDefaults()
  grEstim$withInfectivityProfileMatrix(infProf$yMatrix)
  out = grEstim$estimateGrowthRateSingle(ts, dateColName = "date",incidenceColName = "value")
}

# each estimator function must take a single time series and a single infectivity_profile object and produce a single 
# time series of the estimates. The input time-series will have a "date" and a "value" column.

estimators = tibble(
  model = forcats::as_factor(c(
    "Locfit",
    "Improved Cori",
    "Bayesian"
  )), 
  estimFn = c(
    locfitRtEstimator(2,14),
    improved,
    bayesian
  )
)
```

```{r}
lagAnalysisResult2 = lagAnalysis(estimators, estimation="Rt")

qualityEstimates2 = syntheticEstimates(estimators)
qualityAnalysisResult2 = validationMetrics(qualityEstimates2, modelLag=lagAnalysisResult2$modelLag, estimation="Rt",criticalValue = 1)
 

```

Qualitatively as seen in figure C4 the 3 methods are similar, in that they all faithfully reproduce the true values. A noted in appendix C the locfit method is over-precise compared to the others, and there is little to choose between the Bayesian and renewal equation methods.

```{r}

 
p3 = qualityAnalysisResult2 %>% estimationExamplePlot()
p3 %>% saveHalfPageFigure(output("qualitative-bayesian-rt"))

```

*Figure C4: qualitative estimates of $R_t$ (black) against simulated (red) comparing the Bayesian estimator described here with the maximum likelihood Poisson model implementation from Appendix C and the renewal equation method from Appendix B*

The timing of the estimates showin in Figure C5 are also similar between the Bayesian and renewal equation methods although we note again that the BAyesian method cannot produce estimates up to the end of the timeseries, however this is partly offset by those estimates having less lag.

```{r}
lagAnalysisResult2 %>% lagPlot() %>% saveThirdPageFigure(output("lag-bayesian-rt"))
```

*Figure C5: time delay analysis of $R_t$ (black) against simulated (red) comparing the Bayesian estimator described here with the maximum likelihood Poisson model implementation from Appendix C and the renewal equation method from Appendix B*

Quantitative analysis shows little to separate the renewal equation and this Bayesian method, with the renewal equation method being slightly better calibrated.

```{r}

p = estimateSummaryPlot(qualityAnalysisResult2)
p %>% saveHalfPageFigure(output("error-summary-bayesian-rt"))

```

*Figure C6: Estimate quality metric summaries for multiple estimation methods. In this instance we compare the Bayesian estimator described here with the maximum likelihood Poisson model implementation from Appendix C and the renewal equation method from Appendix B. Panel A show summary statistics for the bias of $R_t$ estimates, panel B shows the calibration. Panel C shows the quantile density, panel D the CRPS and panel E the critical threshold calibration.*

*Table C2: summary of quantitative analysis of $R_t$ (black) against simulated (red) comparing the Bayesian estimator described here with the maximum likelihood Poisson model implementation from Appendix C and the renewal equation method from Appendix B*

```{r}
summaryAnalysis(qualityAnalysisResult2,lagAnalysisResult2) %>% standardPrintOutput::saveTable(output("error-summary-bayesian-rt-table"),defaultFontSize = 7)
```

Detailed breakdowns did not provide any further insight into the differences between the methods.

# Summary

We introduced an alternative bayesian framework for estimating case incidence, growth rate and reproduction number as the same time. This is robust to a range of different synthetic scenarios and performs in a very similar manner to the locally fitted polynomial for growth rate and to the best performing renewal equation method. The estimates are slightly reduced in valueby the fact they cannot estimate right up to the end of the time series, unlike the other methods, but provide welcome validation by which to benchmark the other methods. 

